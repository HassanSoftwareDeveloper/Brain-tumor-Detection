{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCBwwhrKcDA3"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # LongiTumorSense Model Training\n",
        "# **Training on MU-Glioma-Post Dataset**\n",
        "# - Segmentation: nnUNet\n",
        "# - Classification: 3D DenseNet\n",
        "# - Survival: CoxPH Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai torch torchvision nnunet pyradiomics lifelines pydicom nibabel wandb -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "pj30ECgHC42a",
        "outputId": "14974d70-b377-412e-b30d-49e01beb9080"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3735183003.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install monai torch torchvision nnunet pyradiomics lifelines pydicom nibabel wandb -q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m   1085\u001b[0m     return {\n\u001b[1;32m   1086\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1087\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1088\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m     }\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_egginfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mmake_files\u001b[0;34m(lines)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmake_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_egginfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mmake_file\u001b[0;34m(name, hash, size_str)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmake_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_str\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackagePath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFileHash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhash\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_str\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msize_str\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, *args)\u001b[0m\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mPurePath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPureWindowsPath\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mPurePosixPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_parts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;31m# We need to call _parse_args on the instance, so as to get the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;31m# right flavour.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m         \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m         \u001b[0mdrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiq-ZeBbCbIA"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import numpy  as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import os\n",
        "import monai\n",
        "from monai.data import Dataset ,DataLoader\n",
        "from monai.transforms import ( Compose , LoadImaged , EnsureChannelFirstd, ScaleIntensityd,RandRotated,RandFlipd,RandZoomd,ToTensord)\n",
        "from monai.networks.nets import DenseNet121,Unet\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss, FocalLoss\n",
        "import wandb\n",
        "import pandas as pd\n",
        "from lifelines import CoxPHFitter\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "1C4DKCohFTg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTTpC4VwC0Do",
        "outputId": "b472a090-3d10-4288-cfa3-637d38b81f32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device.\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"Using {device} device.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2YW8EoXMYN2",
        "outputId": "e5a8eee4-669f-4064-a2a7-b3ec0c285675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Clearner and saved into the drive**"
      ],
      "metadata": {
        "id": "Ri04EaJBM6Oh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8OKuE6ycWJn",
        "outputId": "9f1461b1-92f9-416a-ef60-1817652f4915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw dataset path: /content/drive/My Drive/MU-Glioma-Post\n",
            "nnU-Net dataset path: /content/drive/My Drive/clean_data\n",
            "Found 4 cases already processed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "raw_root = \"/content/drive/My Drive/MU-Glioma-Post\"\n",
        "\n",
        "output_root=\"/content/drive/My Drive/clean_data\"\n",
        "\n",
        "\n",
        "\n",
        "imagesTr = os.path.join(output_root, \"imagesTr\")\n",
        "labelsTr = os.path.join(output_root, \"labelsTr\")\n",
        "os.makedirs(os.path.join(output_root, \"imagesTs\"), exist_ok=True)\n",
        "os.makedirs(imagesTr, exist_ok=True)\n",
        "os.makedirs(labelsTr, exist_ok=True)\n",
        "\n",
        "print(\"Raw dataset path:\", raw_root)\n",
        "print(\"nnU-Net dataset path:\", output_root)\n",
        "\n",
        "\n",
        "progress_file = os.path.join(output_root, \"converted_cases.txt\")\n",
        "\n",
        "if os.path.exists(progress_file):\n",
        "    with open(progress_file, \"r\") as f:\n",
        "        converted_cases = set(line.strip() for line in f)\n",
        "else:\n",
        "    converted_cases = set()\n",
        "print(f\"Found {len(converted_cases)} cases already processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqpZTvVpf7mf"
      },
      "outputs": [],
      "source": [
        "def is_nifti(fname):\n",
        "  return fname.endswith(\".nii\") or fname.endswith(\".nii.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYZeKxppgCo3"
      },
      "outputs": [],
      "source": [
        "mod_priority=[\n",
        "      't1c','t1gd','t1ce',  # contrast-enhanced T1 variants\n",
        "    't1n','t1',           # native T1\n",
        "    'flair','t2f','t2flair','t2w','t2' # T2 /flair variants\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Iev103XgQPf"
      },
      "outputs": [],
      "source": [
        "def file_priority(fname):\n",
        "  lf=fname.lower()\n",
        "  for i,k in enumerate(mod_priority):\n",
        "    if k in lf:\n",
        "      return i\n",
        "  return len(mod_priority) + hash(lf) % 1000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "canonical_modalities = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "skipped = []\n",
        "new_cases_count = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "total_timepoints = sum(\n",
        "    1 for p in sorted(os.listdir(raw_root))\n",
        "    if os.path.isdir(os.path.join(raw_root, p))\n",
        "    for tp in sorted(os.listdir(os.path.join(raw_root, p)))\n",
        "    if os.path.isdir(os.path.join(raw_root, p, tp))\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with tqdm(total=total_timepoints, desc=\"Processing cases\") as pbar:\n",
        "    for patient_id in sorted(os.listdir(raw_root)):\n",
        "        patient_path = os.path.join(raw_root, patient_id)\n",
        "        if not os.path.isdir(patient_path):\n",
        "            pbar.update(1)\n",
        "            continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for tp in sorted(os.listdir(patient_path)):\n",
        "            tp_path = os.path.join(patient_path, tp)\n",
        "            if not os.path.isdir(tp_path):\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "            tp_clean = re.sub(r\"\\s+\", \"_\", tp)\n",
        "            tp_clean = re.sub(r\"[^A-Za-z0-9_-]\", \"_\", tp_clean)\n",
        "            case_id = f\"{patient_id}_{tp_clean}\"\n",
        "\n",
        "\n",
        "\n",
        "            if case_id in converted_cases:\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "            files = [f for f in os.listdir(tp_path) if is_nifti(f)]\n",
        "            if not files:\n",
        "                skipped.append((patient_id, tp, \"no nifti files\"))\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "            label_candidates = [f for f in files if any(x in f.lower() for x in [\"mask\", \"tumor\", \"seg\", \"label\"])]\n",
        "            if len(label_candidates) == 0:\n",
        "                skipped.append((patient_id, tp, \"no label found\"))\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "            label_file = label_candidates[0]\n",
        "\n",
        "\n",
        "\n",
        "            image_files = [f for f in files if f != label_file]\n",
        "            if len(image_files) == 0:\n",
        "                skipped.append((patient_id, tp, \"no image files\"))\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "            image_files_sorted = sorted(image_files, key=file_priority)\n",
        "            if canonical_modalities is None:\n",
        "                canonical_modalities = image_files_sorted.copy()\n",
        "                print(\"\\nDetected modality order (from first sample)\")\n",
        "                for idx, nm in enumerate(canonical_modalities):\n",
        "                    print(f\"{idx}: {nm}\")\n",
        "                print(\"If this order is wrong adjust mod_priority list in the script.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                if len(image_files_sorted) != len(canonical_modalities):\n",
        "                    skipped.append(\n",
        "                        (patient_id, tp, f\"modality count mismatch {len(image_files_sorted)} vs {len(canonical_modalities)}\")\n",
        "                    )\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "\n",
        "\n",
        "\n",
        "            for i, fname in enumerate(image_files_sorted):\n",
        "                src = os.path.join(tp_path, fname)\n",
        "                destination = os.path.join(imagesTr, f\"{case_id}_{i:04d}.nii.gz\")\n",
        "                shutil.copy(src, destination)\n",
        "\n",
        "            shutil.copy2(os.path.join(tp_path, label_file), os.path.join(labelsTr, f\"{case_id}.nii.gz\"))\n",
        "\n",
        "\n",
        "\n",
        "            converted_cases.add(case_id)\n",
        "            with open(progress_file, \"a\") as f:\n",
        "                f.write(case_id + \"\\n\")\n",
        "\n",
        "            new_cases_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "print(f\"\\nConversion finished. {len(converted_cases)} total cases processed so far.\")\n",
        "if skipped:\n",
        "    print(f\"{len(skipped)} timepoints skipped (see sample):\")\n",
        "    for s in skipped[:10]:\n",
        "        print(\" \", s)\n",
        "\n",
        "print(f\"imagesTr files: {len(os.listdir(imagesTr))}, labelsTr files: {len(os.listdir(labelsTr))}\")\n",
        "print(f\"Newly processed this run: {new_cases_count}\")"
      ],
      "metadata": {
        "id": "0n_o0C16-mDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/nnUNet_raw_data_base\n"
      ],
      "metadata": {
        "id": "7dNiUvJTXAjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get clean data from drive into local colab  with correct file naming structure and create json.data file according to nnUnet formet**"
      ],
      "metadata": {
        "id": "YyI_fuYGDqA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import shutil\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "config = {\n",
        "    'drive_root': \"/content/drive/MyDrive/clean_data\",\n",
        "    'local_root': \"/content/nnUNet_raw_data_base/nnUNet_raw_data/Task001_MU-Glioma-Post\",\n",
        "    'image_pattern': r\"(PatientID_\\d+)_Timepoint_(\\d+)_(\\d{4})\\.nii\\.gz\",\n",
        "    'label_pattern': r\"(PatientID_\\d+)_Timepoint_(\\d+)\\.nii\\.gz\",\n",
        "    'task_name': \"MU-Glioma-Post\",\n",
        "    'expected_modalities': [\"0000\", \"0001\", \"0002\", \"0003\"],\n",
        "    'create_test_folder': False,\n",
        "    'handle_missing_modalities': \"create_empty\",\n",
        "    'strict_validation': True\n",
        "}\n",
        "\n",
        "\n",
        "modality_map = {\n",
        "    \"0000\": {\"suffix\": \"0000\", \"name\": \"t1gd\", \"order\": 0},\n",
        "    \"0001\": {\"suffix\": \"0001\", \"name\": \"t1\", \"order\": 1},\n",
        "    \"0002\": {\"suffix\": \"0002\", \"name\": \"t2\", \"order\": 2},\n",
        "    \"0003\": {\"suffix\": \"0003\", \"name\": \"flair\", \"order\": 3}\n",
        "}\n",
        "\n",
        "def create_empty_volume(reference_nii_path, output_path):\n",
        "    \"\"\"Create float32 NIfTI volume matching reference geometry\"\"\"\n",
        "    try:\n",
        "        ref_img = nib.load(reference_nii_path)\n",
        "        empty_data = np.zeros(ref_img.shape, dtype=np.float32)\n",
        "        empty_img = nib.Nifti1Image(empty_data, ref_img.affine, ref_img.header)\n",
        "        nib.save(empty_img, output_path)\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to create empty volume: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "paths = {\n",
        "    'source_images': os.path.join(config['drive_root'], \"imagesTr\"),\n",
        "    'source_labels': os.path.join(config['drive_root'], \"labelsTr\"),\n",
        "    'dest_images': os.path.join(config['local_root'], \"imagesTr\"),\n",
        "    'dest_labels': os.path.join(config['local_root'], \"labelsTr\"),\n",
        "}\n",
        "\n",
        "\n",
        "os.makedirs(paths['dest_images'], exist_ok=True)\n",
        "os.makedirs(paths['dest_labels'], exist_ok=True)\n",
        "if config['create_test_folder']:\n",
        "    paths['dest_imagesTs'] = os.path.join(config['local_root'], \"imagesTs\")\n",
        "    os.makedirs(paths['dest_imagesTs'], exist_ok=True)\n",
        "\n",
        "print(\"\\nRunning strict nnU-Net dataset preparation...\")\n",
        "warnings = []\n",
        "errors = []\n",
        "\n",
        "\n",
        "case_counter = 1\n",
        "patient_mapping = {}\n",
        "case_data = defaultdict(dict)\n",
        "\n",
        "for fname in tqdm(os.listdir(paths['source_images']), desc=\"Processing images\"):\n",
        "    match = re.match(config['image_pattern'], fname)\n",
        "    if not match:\n",
        "        warnings.append(f\"SKIPPED: Invalid image filename - {fname}\")\n",
        "        continue\n",
        "\n",
        "    patient_id, _, modality_idx = match.groups()\n",
        "\n",
        "    if patient_id not in patient_mapping:\n",
        "        case_id = f\"Case_{case_counter:04d}\"\n",
        "        patient_mapping[patient_id] = case_id\n",
        "        case_counter += 1\n",
        "\n",
        "    case_id = patient_mapping[patient_id]\n",
        "    modality_info = modality_map.get(modality_idx)\n",
        "\n",
        "    if not modality_info:\n",
        "        warnings.append(f\"SKIPPED: Unknown modality {modality_idx} in {fname}\")\n",
        "        continue\n",
        "\n",
        "    new_name = f\"{case_id}_{modality_info['suffix']}.nii.gz\"\n",
        "    src = os.path.join(paths['source_images'], fname)\n",
        "    dest = os.path.join(paths['dest_images'], new_name)\n",
        "\n",
        "    try:\n",
        "        shutil.copyfile(src, dest)\n",
        "        case_data[case_id].setdefault(\"modalities\", []).append(modality_info)\n",
        "        if len(case_data[case_id][\"modalities\"]) == 1:\n",
        "            case_data[case_id][\"reference_volume\"] = dest\n",
        "    except Exception as e:\n",
        "        errors.append(f\"COPY FAILED: {src} → {dest} | {str(e)}\")\n",
        "\n",
        "\n",
        "for fname in tqdm(os.listdir(paths['source_labels']), desc=\"Processing labels\"):\n",
        "    match = re.match(config['label_pattern'], fname)\n",
        "    if not match:\n",
        "        warnings.append(f\"SKIPPED: Invalid label filename - {fname}\")\n",
        "        continue\n",
        "\n",
        "    patient_id, _ = match.groups()\n",
        "\n",
        "    if patient_id not in patient_mapping:\n",
        "        errors.append(f\"ORPHAN LABEL: No matching images for {fname}\")\n",
        "        continue\n",
        "\n",
        "    case_id = patient_mapping[patient_id]\n",
        "    new_name = f\"{case_id}.nii.gz\"\n",
        "    src = os.path.join(paths['source_labels'], fname)\n",
        "    dest = os.path.join(paths['dest_labels'], new_name)\n",
        "\n",
        "    try:\n",
        "        shutil.copyfile(src, dest)\n",
        "        case_data[case_id][\"label_exists\"] = True\n",
        "    except Exception as e:\n",
        "        errors.append(f\"LABEL COPY FAILED: {src} → {dest} | {str(e)}\")\n",
        "\n",
        "\n",
        "cases_to_remove = []\n",
        "for case_id, data in case_data.items():\n",
        "\n",
        "    if \"modalities\" not in data:\n",
        "        errors.append(f\"NO IMAGES: {case_id} has no valid images\")\n",
        "        cases_to_remove.append(case_id)\n",
        "        continue\n",
        "\n",
        "    if not data.get(\"label_exists\"):\n",
        "        if config['strict_validation']:\n",
        "            errors.append(f\"MISSING LABEL: {case_id} has images but no label\")\n",
        "            cases_to_remove.append(case_id)\n",
        "        else:\n",
        "            warnings.append(f\"UNLABELED CASE: {case_id} has no label (skipping)\")\n",
        "            cases_to_remove.append(case_id)\n",
        "        continue\n",
        "\n",
        "\n",
        "    found_modalities = {m[\"suffix\"] for m in data[\"modalities\"]}\n",
        "    missing_modalities = set(config['expected_modalities']) - found_modalities\n",
        "\n",
        "    if missing_modalities:\n",
        "        if config['handle_missing_modalities'] == \"skip_case\":\n",
        "            cases_to_remove.append(case_id)\n",
        "            warnings.append(f\"REMOVING CASE: {case_id} missing modalities {sorted(missing_modalities)}\")\n",
        "        elif config['handle_missing_modalities'] == \"create_empty\":\n",
        "            for mod in missing_modalities:\n",
        "                empty_path = os.path.join(paths['dest_images'], f\"{case_id}_{mod}.nii.gz\")\n",
        "                if create_empty_volume(data[\"reference_volume\"], empty_path):\n",
        "                    case_data[case_id][\"modalities\"].append(modality_map[mod])\n",
        "                    warnings.append(f\"CREATED EMPTY: {case_id}_{mod}.nii.gz\")\n",
        "                else:\n",
        "                    errors.append(f\"EMPTY VOLUME FAILED: {case_id}_{mod}.nii.gz\")\n",
        "                    cases_to_remove.append(case_id)\n",
        "                    break\n",
        "\n",
        "\n",
        "for cid in set(cases_to_remove):\n",
        "    case_data.pop(cid, None)\n",
        "\n",
        "# ==================== GENERATE DATASET.JSON ====================\n",
        "modality_list = sorted(modality_map.values(), key=lambda x: x['order'])\n",
        "\n",
        "# ====== 1. PRE-VALIDATION ======\n",
        "print(\"Running pre-validation checks...\")\n",
        "\n",
        "# Check if dataset is single or multi-modal\n",
        "is_multimodal = len(modality_list) > 1\n",
        "print(f\"Dataset type: {'Multi-modal' if is_multimodal else 'Single-modal'}\")\n",
        "\n",
        "# Verify all expected files exist\n",
        "all_files_valid = True\n",
        "for case_id, data in case_data.items():\n",
        "    if not data.get(\"label_exists\"):\n",
        "        continue\n",
        "\n",
        "    # Check modalities\n",
        "    for m in modality_list:\n",
        "        img_path = os.path.join(paths['dest_images'], f\"{case_id}_{m['suffix']}.nii.gz\")\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"Missing image: {img_path}\")\n",
        "            all_files_valid = False\n",
        "\n",
        "    # Check label\n",
        "    label_path = os.path.join(paths['dest_labels'], f\"{case_id}.nii.gz\")\n",
        "    if not os.path.exists(label_path):\n",
        "        print(f\"Missing label: {label_path}\")\n",
        "        all_files_valid = False\n",
        "\n",
        "if not all_files_valid:\n",
        "    raise ValueError(\"Pre-validation failed: Missing files detected\")\n",
        "\n",
        "# ====== 2. DATASET GENERATION ======\n",
        "dataset_json = {\n",
        "    \"name\": config['task_name'],\n",
        "    \"description\": \"Post-operative glioma segmentation\",\n",
        "    \"reference\": \"Your reference here\",\n",
        "    \"licence\": \"Your license here\",\n",
        "    \"release\": \"1.0\",\n",
        "    \"modality\": {str(i): m[\"name\"] for i, m in enumerate(modality_list)},\n",
        "    \"labels\": {\n",
        "        \"0\": \"background\",\n",
        "        \"1\": \"tumor\"\n",
        "    },\n",
        "    \"numTraining\": len([c for c in case_data.values() if c.get(\"label_exists\")]),\n",
        "    \"numTest\": 0,\n",
        "    \"training\": [],\n",
        "    \"test\": []\n",
        "}\n",
        "\n",
        "for case_id, data in case_data.items():\n",
        "    if not data.get(\"label_exists\"):\n",
        "        continue\n",
        "\n",
        "    # Get modalities in correct order\n",
        "    available_modalities = []\n",
        "    for m in modality_list:  # Follow predefined modality order\n",
        "        img_path = os.path.join(paths['dest_images'], f\"{case_id}_{m['suffix']}.nii.gz\")\n",
        "        if os.path.exists(img_path):\n",
        "            available_modalities.append(m)\n",
        "\n",
        "    # Create paths - guaranteed correct order\n",
        "    image_paths = [f\"./imagesTr/{case_id}_{m['suffix']}.nii.gz\" for m in available_modalities]\n",
        "\n",
        "    # CRITICAL: Force consistent format based on dataset type\n",
        "    if is_multimodal:\n",
        "        training_entry = {\n",
        "            \"image\": image_paths,  # Always list for multi-modal\n",
        "            \"label\": f\"./labelsTr/{case_id}.nii.gz\"\n",
        "        }\n",
        "    else:\n",
        "        training_entry = {\n",
        "            \"image\": image_paths[0],  # Always string for single-modal\n",
        "            \"label\": f\"./labelsTr/{case_id}.nii.gz\"\n",
        "        }\n",
        "\n",
        "    dataset_json[\"training\"].append(training_entry)\n",
        "\n",
        "# ====== 3. POST-VALIDATION ======\n",
        "print(\"\\nRunning post-validation...\")\n",
        "\n",
        "# Check first 5 cases\n",
        "for i, case in enumerate(dataset_json[\"training\"][:5]):\n",
        "    print(f\"\\nCase {i}:\")\n",
        "    print(f\"Image type: {type(case['image'])}\")\n",
        "    print(f\"Content: {case['image']}\")\n",
        "\n",
        "    # Verify type consistency\n",
        "    if is_multimodal and not isinstance(case['image'], list):\n",
        "        raise ValueError(f\"Case {i} should be multi-modal but got single path\")\n",
        "    if not is_multimodal and not isinstance(case['image'], str):\n",
        "        raise ValueError(f\"Case {i} should be single-modal but got list\")\n",
        "\n",
        "# Verify all paths exist\n",
        "print(\"\\nVerifying file paths...\")\n",
        "for case in dataset_json[\"training\"]:\n",
        "    if is_multimodal:\n",
        "        for img_path in case['image']:\n",
        "            if not os.path.exists(os.path.join(config['local_root'], img_path.replace(\"./\", \"\"))):\n",
        "                raise ValueError(f\"Missing image: {img_path}\")\n",
        "    else:\n",
        "        if not os.path.exists(os.path.join(config['local_root'], case['image'].replace(\"./\", \"\"))):\n",
        "            raise ValueError(f\"Missing image: {case['image']}\")\n",
        "\n",
        "    label_path = os.path.join(config['local_root'], case['label'].replace(\"./\", \"\"))\n",
        "    if not os.path.exists(label_path):\n",
        "        raise ValueError(f\"Missing label: {case['label']}\")\n",
        "\n",
        "# ====== 4. SAFE SAVE ======\n",
        "print(\"\\nSaving dataset.json with atomic write...\")\n",
        "temp_path = os.path.join(config['local_root'], \"dataset.json.tmp\")\n",
        "final_path = os.path.join(config['local_root'], \"dataset.json\")\n",
        "\n",
        "try:\n",
        "    with open(temp_path, 'w') as f:\n",
        "        json.dump(dataset_json, f, indent=4, ensure_ascii=False)\n",
        "    os.replace(temp_path, final_path)\n",
        "except Exception as e:\n",
        "    if os.path.exists(temp_path):\n",
        "        os.remove(temp_path)\n",
        "    raise ValueError(f\"Failed to save dataset.json: {str(e)}\")\n",
        "\n",
        "print(\"\\nDATASET CREATION SUCCESSFUL!\")\n",
        "print(f\"Total training cases: {len(dataset_json['training'])}\")\n",
        "print(f\"Modality order: {[m['name'] for m in modality_list]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f21pDUrwVj_5",
        "outputId": "e0675cc4-37ab-40a1-bdee-2b08df5dcc84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running strict nnU-Net dataset preparation...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 2376/2376 [02:36<00:00, 15.18it/s]\n",
            "Processing labels: 100%|██████████| 594/594 [00:05<00:00, 108.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running pre-validation checks...\n",
            "Dataset type: Multi-modal\n",
            "\n",
            "Running post-validation...\n",
            "\n",
            "Case 0:\n",
            "Image type: <class 'list'>\n",
            "Content: ['./imagesTr/Case_0001_0000.nii.gz', './imagesTr/Case_0001_0001.nii.gz', './imagesTr/Case_0001_0002.nii.gz', './imagesTr/Case_0001_0003.nii.gz']\n",
            "\n",
            "Case 1:\n",
            "Image type: <class 'list'>\n",
            "Content: ['./imagesTr/Case_0002_0000.nii.gz', './imagesTr/Case_0002_0001.nii.gz', './imagesTr/Case_0002_0002.nii.gz', './imagesTr/Case_0002_0003.nii.gz']\n",
            "\n",
            "Case 2:\n",
            "Image type: <class 'list'>\n",
            "Content: ['./imagesTr/Case_0003_0000.nii.gz', './imagesTr/Case_0003_0001.nii.gz', './imagesTr/Case_0003_0002.nii.gz', './imagesTr/Case_0003_0003.nii.gz']\n",
            "\n",
            "Case 3:\n",
            "Image type: <class 'list'>\n",
            "Content: ['./imagesTr/Case_0004_0000.nii.gz', './imagesTr/Case_0004_0001.nii.gz', './imagesTr/Case_0004_0002.nii.gz', './imagesTr/Case_0004_0003.nii.gz']\n",
            "\n",
            "Case 4:\n",
            "Image type: <class 'list'>\n",
            "Content: ['./imagesTr/Case_0005_0000.nii.gz', './imagesTr/Case_0005_0001.nii.gz', './imagesTr/Case_0005_0002.nii.gz', './imagesTr/Case_0005_0003.nii.gz']\n",
            "\n",
            "Verifying file paths...\n",
            "\n",
            "Saving dataset.json with atomic write...\n",
            "\n",
            "DATASET CREATION SUCCESSFUL!\n",
            "Total training cases: 203\n",
            "Modality order: ['t1gd', 't1', 't2', 'flair']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiegR9RiCE9l"
      },
      "source": [
        "**After Disconnect:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IGS3nUAZ22D0"
      },
      "outputs": [],
      "source": [
        "!pip install monai torch torchvision nnunet pyradiomics lifelines pydicom nibabel wandb -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxdV-3ovAz3h"
      },
      "source": [
        "**Install a Python package directly from its GitHub source code, not from the normal package store (PyPI).”**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/MIC-DKFZ/nnUNet.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oUJjbkVCooTX",
        "outputId": "4df1a4c2-ff9e-44a4-993f-a679ba91ce75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/MIC-DKFZ/nnUNet.git\n",
            "  Cloning https://github.com/MIC-DKFZ/nnUNet.git to /tmp/pip-req-build-qolt2mfe\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/MIC-DKFZ/nnUNet.git /tmp/pip-req-build-qolt2mfe\n",
            "  Resolved https://github.com/MIC-DKFZ/nnUNet.git to commit 8c4184d46b60059ff7dc8f74cd535e13554bdeca\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.6.0+cu124)\n",
            "Collecting acvl-utils<0.3,>=0.2.3 (from nnunetv2==2.6.2)\n",
            "  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dynamic-network-architectures<0.5,>=0.4.1 (from nnunetv2==2.6.2)\n",
            "  Downloading dynamic_network_architectures-0.4.2.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (1.16.1)\n",
            "Requirement already satisfied: batchgenerators>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.25.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.25.2)\n",
            "Requirement already satisfied: SimpleITK>=2.2.1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.5.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.21)\n",
            "Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2025.6.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (2.32.3)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.13.2)\n",
            "Collecting imagecodecs (from nnunetv2==2.6.2)\n",
            "  Downloading imagecodecs-2025.8.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (20 kB)\n",
            "Collecting yacs (from nnunetv2==2.6.2)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Collecting batchgeneratorsv2>=0.3.0 (from nnunetv2==2.6.2)\n",
            "  Downloading batchgeneratorsv2-0.3.0.tar.gz (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (0.8.1)\n",
            "Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2==2.6.2) (3.6.1)\n",
            "Collecting connected-components-3d (from acvl-utils<0.3,>=0.2.3->nnunetv2==2.6.2)\n",
            "  Downloading connected_components_3d-3.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (11.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.0.0)\n",
            "Requirement already satisfied: unittest2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2==2.6.2) (3.6.0)\n",
            "Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.3.0->nnunetv2==2.6.2)\n",
            "  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (1.10.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (1.1.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (4.3.8)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (2.11.0)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2==2.6.2) (9.0.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (from dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (1.0.19)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (2.37.0)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2==2.6.2) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (4.14.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2==2.6.2) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2==2.6.2) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2==2.6.2) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2==2.6.2) (6.5.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2==2.6.2) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2==2.6.2) (2025.8.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2==2.6.2) (1.5.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2==2.6.2) (6.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2==2.6.2) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2==2.6.2) (3.0.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.21.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.34.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (0.6.2)\n",
            "Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: traceback2 in /usr/local/lib/python3.11/dist-packages (from unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm->dynamic-network-architectures<0.5,>=0.4.1->nnunetv2==2.6.2) (1.1.7)\n",
            "Requirement already satisfied: linecache2 in /usr/local/lib/python3.11/dist-packages (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2==2.6.2) (1.0.0)\n",
            "Downloading imagecodecs-2025.8.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (26.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading connected_components_3d-3.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n",
            "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Building wheels for collected packages: nnunetv2, acvl-utils, batchgeneratorsv2, dynamic-network-architectures\n",
            "  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nnunetv2: filename=nnunetv2-2.6.2-py3-none-any.whl size=285339 sha256=53a62a2a375bf4ac9e7eb7911ac9e43506349bdac147847eb6f1e27fd864d02f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7p7s6wgs/wheels/04/75/d0/d7ebfc2fa0b1f4599990ff4185318c5f2ebb337f88806d6b76\n",
            "  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for acvl-utils: filename=acvl_utils-0.2.5-py3-none-any.whl size=27213 sha256=dab30f5491187a8f00af7ade432afa2455c967542cee49bd2e7ccf1eeab77d5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/8c/10/dcba79e0b2d1d463605233cec1fc6cfad47af5230b8985e464\n",
            "  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.3.0-py3-none-any.whl size=65215 sha256=0ce9e4ff38f3039f56511cee84041483c10262f2e4f98516132307e99c56dfe8\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/c1/8f/94ca60255dbbadf27e1da4885002a6943c95b067b8e2dd39ea\n",
            "  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.4.2-py3-none-any.whl size=39025 sha256=1ae0da380539d77b48539a4898654495579d50a05babec798b611fbdda9eca86\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/a9/c3/fcdf69ef4481860db91d0dc2466f63df8c3933262424a23f54\n",
            "Successfully built nnunetv2 acvl-utils batchgeneratorsv2 dynamic-network-architectures\n",
            "Installing collected packages: argparse, yacs, imagecodecs, connected-components-3d, fft-conv-pytorch, acvl-utils, batchgeneratorsv2, dynamic-network-architectures, nnunetv2\n",
            "Successfully installed acvl-utils-0.2.5 argparse-1.4.0 batchgeneratorsv2-0.3.0 connected-components-3d-3.24.0 dynamic-network-architectures-0.4.2 fft-conv-pytorch-1.2.0 imagecodecs-2025.8.2 nnunetv2-2.6.2 yacs-0.1.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "3b9102148d644003bf83f1d5d9c08524"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEzaBMYLCTVI"
      },
      "source": [
        "**This function loads an MRI file, converts it to a NumPy array, and scales all values to between 0 and 1 for easier analysis.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YOcMNyv3YC7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr2v-669CSwg"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import numpy  as np\n",
        "\n",
        "def load_and_preprocess(patient_path):\n",
        "    img = nib.load(patient_path)\n",
        "    data = img.get_fdata()\n",
        "    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**delete 0 bytes files**"
      ],
      "metadata": {
        "id": "rFqWhfXLL5e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def clean_zero_byte_files(folder_path, verbose=True):\n",
        "    \"\"\"Safely delete 0-byte files and verify deletions.\n",
        "\n",
        "    Args:\n",
        "        folder_path: Path to directory to clean\n",
        "        verbose: Whether to print deletion messages\n",
        "\n",
        "    Returns:\n",
        "        tuple: (deleted_files, failed_deletions)\n",
        "    \"\"\"\n",
        "    deleted_files = []\n",
        "    failed_deletions = []\n",
        "\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "\n",
        "            try:\n",
        "\n",
        "                if os.path.isfile(file_path) and os.path.getsize(file_path) == 0:\n",
        "                    if verbose:\n",
        "                        print(f\"Deleting 0-byte file: {file_path}\")\n",
        "\n",
        "                    os.remove(file_path)\n",
        "\n",
        "\n",
        "                    if not os.path.exists(file_path):\n",
        "                        deleted_files.append(file_path)\n",
        "                    else:\n",
        "                        failed_deletions.append(file_path)\n",
        "                        if verbose:\n",
        "                            print(f\"Failed to delete: {file_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                failed_deletions.append(file_path)\n",
        "                if verbose:\n",
        "                    print(f\"Error processing {file_path}: {str(e)}\")\n",
        "\n",
        "    return deleted_files, failed_deletions\n",
        "\n",
        "\n",
        "deleted_images, failed_images = clean_zero_byte_files(\"/content/nnUNet_raw_data_base/nnUNet_raw_data/Task001_MU-Glioma-Post/imagesTr\")\n",
        "deleted_labels, failed_labels = clean_zero_byte_files(\"/content/nnUNet_raw_data_base/nnUNet_raw_data/Task001_MU-Glioma-Post/labelsTr\")\n",
        "\n",
        "print(f\"\\nResults:\")\n",
        "print(f\"Deleted {len(deleted_images)} image files\")\n",
        "print(f\"Failed to delete {len(failed_images)} image files\")\n",
        "print(f\"Deleted {len(deleted_labels)} label files\")\n",
        "print(f\"Failed to delete {len(failed_labels)} label files\\n\")\n",
        "\n",
        "if failed_images or failed_labels:\n",
        "    print(\"Warning: Some files couldn't be deleted. Check permissions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2w42vLvcG3g",
        "outputId": "efee53fd-de23-466b-a212-c5a3496bef88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "Deleted 0 image files\n",
            "Failed to delete 0 image files\n",
            "Deleted 0 label files\n",
            "Failed to delete 0 label files\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkjWjNWHBBdW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Print your default W&B username (entity)\n",
        "print(\"Your W&B username:\", wandb.Api().default_entity)\n",
        "\n",
        "# Alternative: Check after login\n",
        "wandb.login()\n",
        "print(\"Logged in as:\", wandb.Api().default_entity)"
      ],
      "metadata": {
        "id": "VRxzFScnoqqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"LongiTumorSense\",entity=\"numl-f21-35629-numl\")"
      ],
      "metadata": {
        "id": "vJa0eTVtEgpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def prepare_dataset(imagesTr, labelsTr, test_size=0.2):\n",
        "\n",
        "    image_files = [f for f in os.listdir(imagesTr) if f.endswith(\".nii.gz\")]\n",
        "    case_ids = sorted(list(set(\"_\".join(f.split(\"_\")[:-1]) for f in image_files)))\n",
        "\n",
        "    print(f\"Found {len(case_ids)} unique cases.\")\n",
        "\n",
        "    # Split into train and test\n",
        "    train_cases, test_cases = train_test_split(case_ids, test_size=test_size, random_state=42)\n",
        "\n",
        "    missing_labels = []\n",
        "\n",
        "    def build_file_list(cases):\n",
        "        file_list = []\n",
        "        for case_id in cases:\n",
        "            # Build list of all 4 modalities for this case\n",
        "            modalities = [\n",
        "                os.path.join(imagesTr, f\"{case_id}_0000.nii.gz\"),  # FLAIR\n",
        "                os.path.join(imagesTr, f\"{case_id}_0001.nii.gz\"),  # T1\n",
        "                os.path.join(imagesTr, f\"{case_id}_0002.nii.gz\"),  # T1ce\n",
        "                os.path.join(imagesTr, f\"{case_id}_0003.nii.gz\")   # T2\n",
        "            ]\n",
        "            label_path = os.path.join(labelsTr, f\"{case_id}.nii.gz\")\n",
        "\n",
        "            if not os.path.exists(label_path):\n",
        "                missing_labels.append(case_id)\n",
        "                continue\n",
        "\n",
        "            file_list.append({\n",
        "                \"image\": modalities,\n",
        "                \"label\": label_path,\n",
        "                \"name\": case_id\n",
        "            })\n",
        "        return file_list\n",
        "\n",
        "    train_files = build_file_list(train_cases)\n",
        "    test_files = build_file_list(test_cases)\n",
        "\n",
        "    print(f\"Length of training dataset: {len(train_files)}\")\n",
        "    print(f\"Length of validation dataset: {len(test_files)}\")\n",
        "\n",
        "    if missing_labels:\n",
        "        print(f\"Missing labels for {len(missing_labels)} cases: {missing_labels[:10]}{'...' if len(missing_labels) > 10 else ''}\")\n",
        "\n",
        "    return train_files, test_files\n"
      ],
      "metadata": {
        "id": "J7q_yUWaiEj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_files, test_files = prepare_dataset(\n",
        "    \"/content/clean_data_local/imagesTr\",\n",
        "    \"/content/clean_data_local/labelsTr\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd4Qh8G7Z7Us",
        "outputId": "79b869fb-0d1d-4f0e-af0a-16aadf361893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 594 unique cases.\n",
            "Length of training dataset: 474\n",
            "Length of validation dataset: 119\n",
            "Missing labels for 1 cases: ['PatientID_0275_Timepoint_6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwp0vLhAMGLZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**this is used for skipped bad , unreachable ,missing samples instead of crashing**"
      ],
      "metadata": {
        "id": "GkxhivpdbilD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import LoadImaged\n",
        "from monai.data import Dataset as MonaiDataset,DataLoader\n",
        "class SafeDataset(MonaiDataset):\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        try:\n",
        "            if self.transform is not None:\n",
        "                transformed_item = self.transform(item)\n",
        "                if transformed_item is not None:\n",
        "                    return transformed_item\n",
        "                else:\n",
        "                    image=item.get(\"image\",\"unknown\")\n",
        "                    print(f\"Skipping sample at index: {index}:{image} (Transform returned None)\")\n",
        "                    return None\n",
        "\n",
        "            return item\n",
        "\n",
        "        except (FileNotFoundError, nib.filebasedimages.ImageFileError, RuntimeError)  as e:\n",
        "              image=item.get(\"image\",\"unknown\")\n",
        "              print(f\"Skipping sample at index: {index}:{image} ({e})\")\n",
        "              return None\n",
        "        except Exception as e:\n",
        "             image= item.get(\"image\",\"unknown\")\n",
        "             print(f\"Skipping sample at index:  {index} due to unexpected error: {image} ({e})\")\n",
        "             return None"
      ],
      "metadata": {
        "id": "nlhNxvRsmRi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**t checks the batch list, kicks out the None entries, and only lets valid data into the collate party. **"
      ],
      "metadata": {
        "id": "CZIdBJt_b_KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data._utils.collate import default_collate\n",
        "def collate_skip_none(batch):\n",
        "    batch = [item for item in batch if item is not None]\n",
        "    if not batch:\n",
        "        return []\n",
        "    return default_collate(batch)"
      ],
      "metadata": {
        "id": "kXEDwad90kO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load images → put channel first → convert to PyTorch tensor.**"
      ],
      "metadata": {
        "id": "QZvUMnC8cglB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import Compose\n",
        "\n",
        "transform_basic=Compose([\n",
        "    LoadImaged(keys=[\"image\"],allow_missing_keys=True),\n",
        "    EnsureChannelFirstd(keys=[\"image\"]),\n",
        "    ToTensord(keys=[\"image\"])\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "n5kxY5IhcMTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "train_dataset_basic=SafeDataset(data=train_files,transform=transform_basic)\n",
        "train_loader_basic=DataLoader(train_dataset_basic,batch_size=batch_size, collate_fn=collate_skip_none, shuffle=True)\n",
        "batch_shape=next(iter(train_loader_basic))[\"image\"].shape\n",
        "print(\"Getting batches of shape:\",batch_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poHP67I9fkf1",
        "outputId": "2fada7dc-6d0c-4f66-a2b9-36d6e683e3d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting batches of shape: torch.Size([4, 4, 240, 240, 155])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**check original file in drive**"
      ],
      "metadata": {
        "id": "BIrjIItcWGu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def get_mean_std(dataset_loader_basic, resume_file=None, nonzero=True):\n",
        "    \"\"\"\n",
        "    Compute per-channel mean and std from a DataLoader that yields dicts with key 'image'.\n",
        "\n",
        "    Args:\n",
        "        dataset_loader_basic: PyTorch DataLoader returning batches with [\"image\"] tensors\n",
        "                              of shape [B, C, H, W] or [B, C, D, H, W]\n",
        "        resume_file (str or None): Optional file to store the last processed batch index for resuming.\n",
        "        nonzero (bool): If True, compute statistics only over nonzero voxels (ignores background).\n",
        "\n",
        "    Returns:\n",
        "        mean (torch.Tensor): Per-channel mean values.\n",
        "        std (torch.Tensor): Per-channel standard deviations.\n",
        "    \"\"\"\n",
        "    start_index = 0\n",
        "    if resume_file is not None and os.path.exists(resume_file):\n",
        "        with open(resume_file, \"r\") as f:\n",
        "            start_index = int(f.read().strip() or 0)\n",
        "        print(f\"Resuming from batch index {start_index}...\")\n",
        "\n",
        "    first_batch = next(iter(dataset_loader_basic))\n",
        "    num_channels = first_batch[\"image\"].shape[1]\n",
        "\n",
        "    if nonzero:\n",
        "        channels_sum = torch.zeros(num_channels)\n",
        "        channels_squared_sum = torch.zeros(num_channels)\n",
        "        voxel_counts = torch.zeros(num_channels)\n",
        "    else:\n",
        "        channels_sum = torch.zeros(num_channels)\n",
        "        channels_squared_sum = torch.zeros(num_channels)\n",
        "        num_batches = 0\n",
        "\n",
        "    for idx, batch in enumerate(tqdm(dataset_loader_basic, desc=\"Computing mean/std\", unit=\"batch\")):\n",
        "        if idx < start_index:\n",
        "            continue\n",
        "        try:\n",
        "            data = batch[\"image\"].float()\n",
        "\n",
        "            if nonzero:\n",
        "                for c in range(num_channels):\n",
        "                    mask = data[:, c] != 0\n",
        "                    vals = data[:, c][mask]\n",
        "                    if vals.numel() > 0:\n",
        "                        channels_sum[c] += vals.sum()\n",
        "                        channels_squared_sum[c] += (vals ** 2).sum()\n",
        "                        voxel_counts[c] += vals.numel()\n",
        "            else:\n",
        "                dims = list(range(0, data.ndim))\n",
        "                dims.remove(1)\n",
        "                channels_sum += data.mean(dim=dims)\n",
        "                channels_squared_sum += (data ** 2).mean(dim=dims)\n",
        "                num_batches += 1\n",
        "\n",
        "            if resume_file is not None:\n",
        "                with open(resume_file, \"w\") as f:\n",
        "                    f.write(str(idx + 1))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch {idx}: {e}\")\n",
        "\n",
        "    if nonzero:\n",
        "        if (voxel_counts == 0).any():\n",
        "            raise ValueError(\"Some channels have no nonzero voxels.\")\n",
        "        mean = channels_sum / voxel_counts\n",
        "        std = torch.sqrt(channels_squared_sum / voxel_counts - mean ** 2)\n",
        "    else:\n",
        "        if num_batches == 0:\n",
        "            raise ValueError(\"No valid images found in the dataset.\")\n",
        "        mean = channels_sum / num_batches\n",
        "        std = torch.sqrt(channels_squared_sum / num_batches - mean ** 2)\n",
        "\n",
        "    return mean, std\n"
      ],
      "metadata": {
        "id": "N_3kL5bhKu9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean, std = get_mean_std(train_loader_basic,resume_file=None)\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Std:\", std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2GfSZ_gcz3A",
        "outputId": "8d9c42cb-9bdf-4ea8-e5b4-6f096b1d564a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std:  66%|██████▋   | 79/119 [08:13<04:14,  6.36s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping sample at index: 261:['/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0000.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0001.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0002.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0003.nii.gz'] (applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7a4f006b15d0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std: 100%|██████████| 119/119 [12:22<00:00,  6.24s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor([305.7782, 271.5573, 247.0512, 447.8155])\n",
            "Std: tensor([218.4011, 160.3656, 143.3827, 233.6108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M4QzyL6WNaf"
      },
      "outputs": [],
      "source": [
        "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, NormalizeIntensityd, RandRotated, RandFlipd, RandZoomd, ToTensord\n",
        "\n",
        "train_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    # ScaleIntensityd(keys=[\"image\"]),\n",
        "    NormalizeIntensityd(\n",
        "        keys=[\"image\"],\n",
        "        subtrahend=mean.tolist(),\n",
        "        divisor=std.tolist(),\n",
        "        channel_wise=True,\n",
        "        nonzero=True\n",
        "    ),\n",
        "    RandRotated(keys=[\"image\", \"label\"], range_x=0.3, prob=0.5),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5),\n",
        "    RandZoomd(keys=[\"image\", \"label\"], min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
        "    ToTensord(keys=[\"image\", \"label\"]),\n",
        "])\n",
        "\n",
        "test_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    # ScaleIntensityd(keys=[\"image\"]),\n",
        "    NormalizeIntensityd(\n",
        "        keys=[\"image\"],\n",
        "        subtrahend=mean.tolist(),\n",
        "        divisor=std.tolist(),\n",
        "        channel_wise=True,\n",
        "        nonzero=True\n",
        "    ),\n",
        "    ToTensord(keys=[\"image\", \"label\"]),\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuEVd74Ei12y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0703d148-232c-47b7-a2c7-6f14e3e8fd96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting batches of shape: torch.Size([4, 4, 240, 240, 155])\n"
          ]
        }
      ],
      "source": [
        "batch_size=4\n",
        "train_dataset_norm =SafeDataset(data=train_files,transform=train_transforms)\n",
        "dataset_loader_norm=DataLoader(train_dataset_norm,batch_size=batch_size, collate_fn=collate_skip_none)\n",
        "batch = next(iter(dataset_loader_norm))\n",
        "if batch:\n",
        "    batch_shape=batch[\"image\"].shape\n",
        "    print(\"Getting batches of shape:\",batch_shape)\n",
        "else:\n",
        "    print(\"No valid batches were loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "norm_mean, norm_std = get_mean_std(dataset_loader_norm,resume_file=None)\n",
        "\n",
        "print(f\"Mean: {norm_mean}\")\n",
        "print(f\"Standard deviation: {norm_std}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buTOcL_VoA5L",
        "outputId": "0ed66456-bb79-46b3-d082-d73403c73009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std:  55%|█████▍    | 65/119 [22:13<17:56, 19.93s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping sample at index: 261:['/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0000.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0001.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0002.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0003.nii.gz'] (applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7a4f004a7cd0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std: 100%|██████████| 119/119 [39:41<00:00, 20.01s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor([0.0047, 0.0046, 0.0091, 0.0047])\n",
            "Standard deviation: tensor([0.9846, 0.9852, 0.9753, 0.9688])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=2\n",
        "test_dataset_norm=SafeDataset(data=test_files,transform=test_transforms)\n",
        "dataset_loader_test_norm=DataLoader(test_dataset_norm,batch_size=batch_size,collate_fn=collate_skip_none,shuffle=False)\n",
        "batch_shape=next(iter(dataset_loader_test_norm))[\"image\"].shape\n",
        "print(\"Getting batches of shape:\",batch_shape)\n",
        "print(type(test_dataset_norm))"
      ],
      "metadata": {
        "id": "eLGMPnPI98yM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786a588b-dddd-4cf1-a570-69481c86a5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting batches of shape: torch.Size([2, 4, 240, 240, 155])\n",
            "<class '__main__.SafeDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_mean, norm_std = get_mean_std(dataset_loader_test_norm)\n",
        "\n",
        "print(f\"Mean: {norm_mean}\")\n",
        "print(f\"Standard deviation: {norm_std}\")"
      ],
      "metadata": {
        "id": "FtlKOJq3-spn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e664219-9ece-4aa8-f4ab-8aa0086ee19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std:  90%|█████████ | 54/60 [03:36<00:22,  3.71s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping sample at index: 109:['/content/clean_data_local/imagesTr/PatientID_0006_Timepoint_6_0000.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0006_Timepoint_6_0001.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0006_Timepoint_6_0002.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0006_Timepoint_6_0003.nii.gz'] (applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7a4f006a8690>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std: 100%|██████████| 60/60 [03:58<00:00,  3.97s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor([0.2668, 0.2856, 0.2744, 0.2978])\n",
            "Standard deviation: tensor([0.8363, 0.7954, 0.8210, 0.8185])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ws6BPrPaaoe",
        "outputId": "d27d0928-de01-4bc7-9e0c-e462a7994572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'monai.data.dataloader.DataLoader'>\n",
            "<class 'monai.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(type(dataset_loader_norm))\n",
        "print(type(dataset_loader_test_norm))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "length_dataset = len(train_dataset_norm)\n",
        "length_train = int(length_dataset * 0.8)\n",
        "length_remaining = length_dataset - length_train\n",
        "train_subset, remaining_subset = random_split(train_dataset_norm, [length_train, length_remaining])\n",
        "\n",
        "percent_train = np.round(100 * len(train_subset) / length_dataset, 2)\n",
        "\n",
        "print(f\"Train data is {percent_train}% of full data\")"
      ],
      "metadata": {
        "id": "GMUlwK41CwhW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "aa44d2b5-abed-4d5b-ac86-8b3e01dc78ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_dataset_norm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1652035311.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlength_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlength_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_dataset\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlength_remaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlength_dataset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlength_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_subset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlength_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_remaining\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dataset_norm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length_dataset_test = len(test_dataset_norm)\n",
        "length_test = int(length_dataset_test * 0.2)\n",
        "length_remaining_test = length_dataset_test - length_test\n",
        "\n",
        "test_subset, remaining_subset_test = random_split(test_dataset_norm, [length_test, length_remaining_test])\n",
        "\n",
        "percent_test = np.round(100 * len(test_subset) / length_dataset_test, 2)\n",
        "\n",
        "print(f\"Test data is {percent_test}% of full test data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msnun4bFzaOs",
        "outputId": "a335a79f-92d4-4549-b7f1-090a3579e5bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data is 19.33% of full test data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4zGBucN1xZ_"
      },
      "source": [
        "\n",
        "**# Convert dataset to nnUNet format**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['nnUNet_raw_data_base'] = '/content/nnUNet_raw_data_base'\n",
        "os.environ['nnUNet_preprocessed'] = '/content/nnUNet_preprocessed'\n",
        "os.environ['RESULTS_FOLDER'] = '/content/nnUNet_results'\n",
        "\n",
        "\n",
        "os.makedirs('/content/nnUNet_raw_data_base', exist_ok=True)\n",
        "os.makedirs('/content/nnUNet_preprocessed', exist_ok=True)\n",
        "os.makedirs('/content/nnUNet_results', exist_ok=True)\n",
        "\n",
        "print(\"nnUNet_raw_data_base =\", os.environ['nnUNet_raw_data_base'])\n",
        "print(\"nnUNet_preprocessed =\", os.environ['nnUNet_preprocessed'])\n",
        "print(\"RESULTS_FOLDER =\", os.environ['RESULTS_FOLDER'])"
      ],
      "metadata": {
        "id": "6NUyTiJeELDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9a85fee-1aa9-4ad1-d274-a685283a6d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nnUNet_raw_data_base = /content/nnUNet_raw_data_base\n",
            "nnUNet_preprocessed = /content/nnUNet_preprocessed\n",
            "RESULTS_FOLDER = /content/nnUNet_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**inshallah ho jhaye ga**"
      ],
      "metadata": {
        "id": "3_R1kApz87Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "# Configuration\n",
        "config = {\n",
        "    'local_root': \"/content/nnUNet_raw_data_base/nnUNet_raw_data/Task001_MU-Glioma-Post\",\n",
        "    'task_name': \"MU-Glioma-Post\",\n",
        "    'modality_map': {\n",
        "        \"0000\": {\"name\": \"t1gd\", \"order\": 0},\n",
        "        \"0001\": {\"name\": \"t1\", \"order\": 1},\n",
        "        \"0002\": {\"name\": \"t2\", \"order\": 2},\n",
        "        \"0003\": {\"name\": \"flair\", \"order\": 3}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Path setup\n",
        "paths = {\n",
        "    'imagesTr': os.path.join(config['local_root'], \"imagesTr\"),\n",
        "    'labelsTr': os.path.join(config['local_root'], \"labelsTr\"),\n",
        "    'imagesTs': os.path.join(config['local_root'], \"imagesTs\")  # Optional test folder\n",
        "}\n",
        "\n",
        "# 1. Determine actual modality type from files\n",
        "modality_suffixes = set()\n",
        "for f in os.listdir(paths['imagesTr']):\n",
        "    if f.endswith(\".nii.gz\") and \"_\" in f:\n",
        "        suffix = f.split(\"_\")[-1].split(\".\")[0]\n",
        "        if suffix.isdigit():\n",
        "            modality_suffixes.add(suffix)\n",
        "\n",
        "is_multimodal = len(modality_suffixes) > 1\n",
        "print(f\"Dataset type: {'Multi-modal' if is_multimodal else 'Single-modal'}\")\n",
        "print(f\"Found modalities: {sorted(modality_suffixes)}\")\n",
        "\n",
        "# 2. Generate dataset.json with guaranteed correct format\n",
        "dataset_json = {\n",
        "    \"name\": config['task_name'],\n",
        "    \"description\": \"Post-operative glioma segmentation\",\n",
        "    \"reference\": \"Your reference here\",\n",
        "    \"licence\": \"Your license here\",\n",
        "    \"release\": \"1.0\",\n",
        "    \"modality\": {str(i): config['modality_map'][suffix][\"name\"]\n",
        "                for i, suffix in enumerate(sorted(modality_suffixes))},\n",
        "    \"labels\": {\n",
        "        \"0\": \"background\",\n",
        "        \"1\": \"tumor\"\n",
        "    },\n",
        "    \"training\": [],\n",
        "    \"test\": []  # Will be populated below\n",
        "}\n",
        "\n",
        "# 3. Process training cases\n",
        "case_ids = sorted({f.split(\"_\")[0] for f in os.listdir(paths['imagesTr']) if f.endswith(\".nii.gz\")})\n",
        "for case_id in case_ids:\n",
        "    if is_multimodal:\n",
        "        # Multi-modal - sorted list of paths\n",
        "        image_paths = sorted(\n",
        "            [f\"./imagesTr/{f}\" for f in os.listdir(paths['imagesTr'])\n",
        "             if f.startswith(case_id) and f.endswith(\".nii.gz\")],\n",
        "            key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0])\n",
        "        )\n",
        "        training_entry = {\n",
        "            \"image\": image_paths,\n",
        "            \"label\": f\"./labelsTr/{case_id}.nii.gz\"\n",
        "        }\n",
        "    else:\n",
        "        # Single-modal - string path\n",
        "        img_file = next(f for f in os.listdir(paths['imagesTr'])\n",
        "                       if f.startswith(case_id) and f.endswith(\".nii.gz\"))\n",
        "        training_entry = {\n",
        "            \"image\": f\"./imagesTr/{img_file}\",\n",
        "            \"label\": f\"./labelsTr/{case_id}.nii.gz\"\n",
        "        }\n",
        "\n",
        "    # Verify label exists before adding\n",
        "    if os.path.exists(os.path.join(config['local_root'], training_entry['label'][2:])):\n",
        "        dataset_json[\"training\"].append(training_entry)\n",
        "    else:\n",
        "        print(f\"Warning: Missing label for {case_id}\")\n",
        "\n",
        "# 4. Handle test set (if exists)\n",
        "if os.path.exists(paths['imagesTs']):\n",
        "    test_files = [f for f in os.listdir(paths['imagesTs']) if f.endswith(\".nii.gz\")]\n",
        "    dataset_json[\"test\"] = [f\"./imagesTs/{f}\" for f in test_files]\n",
        "    dataset_json[\"numTest\"] = len(test_files)\n",
        "else:\n",
        "    dataset_json[\"test\"] = []\n",
        "    dataset_json[\"numTest\"] = 0\n",
        "\n",
        "dataset_json[\"numTraining\"] = len(dataset_json[\"training\"])\n",
        "\n",
        "# 5. Final validation and save\n",
        "print(\"\\nFinal validation:\")\n",
        "print(f\"Training cases: {dataset_json['numTraining']}\")\n",
        "print(f\"Test cases: {dataset_json['numTest']}\")\n",
        "print(\"First training case:\")\n",
        "print(json.dumps(dataset_json[\"training\"][0], indent=2))\n",
        "\n",
        "output_path = os.path.join(config['local_root'], \"dataset.json\")\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(dataset_json, f, indent=4)\n",
        "\n",
        "print(\"\\nDataset successfully created at:\", output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "nML-In9UFcwj",
        "outputId": "dffbafdc-de4a-4440-a6b3-8d4fc3dc4820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset type: Multi-modal\n",
            "Found modalities: ['0000', '0001', '0002', '0003']\n",
            "Warning: Missing label for Case\n",
            "\n",
            "Final validation:\n",
            "Training cases: 0\n",
            "Test cases: 0\n",
            "First training case:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-463449918.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test cases: {dataset_json['numTest']}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"First training case:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_json\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_root'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dataset.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from collections import defaultdict\n",
        "\n",
        "# 1. First determine REAL modality type from files\n",
        "image_dir = \"/content/nnUNet_raw_data_base/nnUNet_raw_data/Task001_MU-Glioma-Post/imagesTr\"\n",
        "modality_suffixes = set()\n",
        "for f in os.listdir(image_dir):\n",
        "    if f.endswith(\".nii.gz\"):\n",
        "        parts = f.split(\"_\")\n",
        "        if len(parts) > 2:  # Has modality suffix\n",
        "            modality_suffixes.add(parts[-1].split(\".\")[0])\n",
        "\n",
        "is_multimodal = len(modality_suffixes) > 1\n",
        "print(f\"Actual modality type: {'Multi-modal' if is_multimodal else 'Single-modal'}\")\n",
        "print(f\"Found modalities: {sorted(modality_suffixes)}\")\n",
        "\n",
        "# 2. Generate dataset.json with PROPER format\n",
        "dataset_json = {\n",
        "    \"name\": \"MU-Glioma-Post\",\n",
        "    \"description\": \"Post-operative glioma segmentation\",\n",
        "    \"modality\": {str(i): f\"modality_{i}\" for i in range(len(modality_suffixes))},\n",
        "    \"labels\": {\"0\": \"background\", \"1\": \"tumor\"},\n",
        "    \"numTraining\": len([f for f in os.listdir(f\"{image_dir}/../labelsTr\") if f.endswith(\".nii.gz\")]),\n",
        "    \"training\": []\n",
        "}\n",
        "\n",
        "# Get all unique case IDs\n",
        "case_ids = sorted(set(f.split(\"_\")[0] for f in os.listdir(image_dir) if f.endswith(\".nii.gz\")))\n",
        "\n",
        "for case_id in case_ids:\n",
        "    if is_multimodal:\n",
        "        # Multi-modal - use sorted list of paths\n",
        "        image_paths = sorted(\n",
        "            [f\"./imagesTr/{f}\" for f in os.listdir(image_dir)\n",
        "             if f.startswith(case_id) and f.endswith(\".nii.gz\")],\n",
        "            key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0])\n",
        "        ) # Added missing parenthesis here\n",
        "        dataset_json[\"training\"].append({\n",
        "            \"image\": image_paths,\n",
        "            \"label\": f\"./labelsTr/{case_id}.nii.gz\"\n",
        "        })\n",
        "    else:\n",
        "        # Single-modal - use string path\n",
        "        img_file = next(f for f in os.listdir(image_dir)\n",
        "                      if f.startswith(case_id) and f.endswith(\".nii.gz\"))\n",
        "        dataset_json[\"training\"].append({\n",
        "            \"image\": f\"./imagesTr/{img_file}\",\n",
        "            \"label\": f\"./labelsTr/{case_id}.nii.gz\"\n",
        "        })\n",
        "\n",
        "# 3. Save with verification\n",
        "output_path = f\"{image_dir}/../dataset.json\"\n",
        "with open(output_path, 'w') as f:\n",
        "    json.dump(dataset_json, f, indent=4)\n",
        "\n",
        "print(\"\\nFinal validation:\")\n",
        "print(\"First training case:\")\n",
        "print(json.dumps(dataset_json[\"training\"][0], indent=2))\n",
        "print(f\"Image field type: {type(dataset_json['training'][0]['image'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwOk_fOKHZBC",
        "outputId": "0dcecfa1-54e8-4b48-ab6f-8a7859c62bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual modality type: Multi-modal\n",
            "Found modalities: ['0000', '0001', '0002', '0003']\n",
            "\n",
            "Final validation:\n",
            "First training case:\n",
            "{\n",
            "  \"image\": [\n",
            "    \"./imagesTr/Case_0128_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0087_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0187_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0074_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0043_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0032_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0181_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0075_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0064_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0065_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0123_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0161_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0104_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0092_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0142_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0085_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0155_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0110_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0125_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0050_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0101_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0017_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0119_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0095_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0184_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0198_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0168_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0091_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0008_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0098_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0089_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0038_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0190_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0131_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0052_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0036_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0137_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0186_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0144_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0126_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0071_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0014_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0096_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0019_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0167_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0006_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0107_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0059_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0062_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0141_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0021_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0088_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0016_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0057_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0040_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0179_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0169_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0182_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0202_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0042_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0160_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0041_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0192_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0157_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0163_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0090_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0081_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0106_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0034_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0200_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0175_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0072_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0086_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0080_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0048_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0068_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0177_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0030_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0109_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0135_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0069_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0076_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0102_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0185_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0061_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0194_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0015_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0149_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0165_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0082_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0073_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0150_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0113_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0039_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0010_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0159_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0147_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0020_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0156_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0058_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0083_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0117_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0197_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0176_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0120_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0166_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0129_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0084_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0053_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0172_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0145_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0193_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0105_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0099_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0103_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0170_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0046_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0140_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0121_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0031_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0067_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0007_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0133_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0025_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0013_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0124_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0189_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0026_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0112_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0055_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0116_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0173_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0139_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0143_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0097_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0044_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0153_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0009_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0060_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0049_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0056_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0018_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0022_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0012_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0195_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0005_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0146_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0004_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0118_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0191_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0174_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0162_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0196_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0054_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0027_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0003_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0122_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0132_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0063_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0171_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0115_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0203_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0151_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0011_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0183_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0130_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0066_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0047_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0079_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0070_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0152_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0108_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0035_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0029_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0002_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0028_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0154_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0100_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0114_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0051_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0134_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0037_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0045_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0158_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0078_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0093_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0201_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0148_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0024_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0127_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0033_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0023_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0094_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0164_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0001_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0178_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0180_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0188_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0138_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0111_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0199_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0136_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0077_0000.nii.gz\",\n",
            "    \"./imagesTr/Case_0146_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0053_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0031_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0169_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0010_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0071_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0011_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0032_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0135_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0133_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0013_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0041_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0178_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0069_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0111_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0056_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0022_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0172_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0104_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0098_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0197_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0134_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0188_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0067_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0029_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0003_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0045_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0153_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0107_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0014_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0047_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0127_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0155_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0168_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0026_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0086_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0196_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0078_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0020_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0182_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0180_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0066_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0023_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0136_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0009_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0177_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0063_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0174_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0170_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0203_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0122_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0085_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0143_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0191_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0189_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0062_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0165_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0179_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0157_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0080_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0186_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0005_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0198_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0090_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0132_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0065_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0185_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0184_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0159_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0084_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0126_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0108_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0075_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0110_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0058_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0046_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0166_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0068_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0044_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0117_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0081_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0038_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0141_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0192_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0140_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0057_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0019_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0082_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0087_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0036_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0151_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0016_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0035_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0072_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0199_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0190_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0145_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0015_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0123_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0077_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0147_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0121_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0194_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0083_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0171_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0048_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0124_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0061_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0034_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0018_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0202_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0073_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0004_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0193_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0043_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0070_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0093_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0105_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0119_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0113_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0051_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0027_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0106_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0149_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0094_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0138_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0037_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0131_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0039_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0096_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0163_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0167_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0125_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0129_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0173_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0054_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0101_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0033_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0052_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0017_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0064_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0024_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0099_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0079_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0164_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0181_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0200_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0049_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0120_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0118_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0139_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0114_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0187_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0050_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0161_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0002_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0109_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0008_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0142_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0152_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0112_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0137_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0115_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0012_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0001_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0175_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0097_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0144_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0055_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0095_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0092_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0148_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0060_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0201_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0154_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0007_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0130_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0156_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0089_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0103_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0006_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0150_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0128_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0042_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0162_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0100_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0030_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0040_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0028_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0102_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0021_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0025_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0076_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0091_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0176_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0116_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0074_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0088_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0158_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0160_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0059_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0195_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0183_0001.nii.gz\",\n",
            "    \"./imagesTr/Case_0063_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0033_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0029_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0171_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0149_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0111_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0156_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0062_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0174_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0070_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0096_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0086_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0042_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0140_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0145_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0181_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0021_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0045_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0093_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0165_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0037_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0087_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0097_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0050_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0058_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0071_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0129_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0046_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0105_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0157_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0095_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0032_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0075_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0040_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0175_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0134_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0191_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0193_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0023_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0189_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0004_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0110_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0109_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0151_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0054_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0194_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0006_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0123_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0173_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0066_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0195_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0060_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0170_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0180_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0090_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0164_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0169_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0072_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0186_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0141_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0135_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0009_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0182_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0057_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0150_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0064_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0127_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0074_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0155_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0108_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0183_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0179_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0041_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0139_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0153_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0061_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0047_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0016_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0076_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0147_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0031_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0002_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0200_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0114_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0120_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0116_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0007_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0138_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0159_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0176_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0051_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0148_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0154_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0130_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0102_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0059_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0202_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0132_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0143_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0005_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0152_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0136_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0098_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0067_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0118_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0091_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0073_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0008_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0053_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0201_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0196_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0044_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0126_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0089_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0092_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0055_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0188_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0056_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0010_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0185_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0068_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0081_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0048_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0128_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0199_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0049_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0168_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0014_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0011_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0052_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0160_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0099_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0162_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0038_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0184_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0190_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0017_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0133_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0115_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0178_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0119_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0027_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0142_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0122_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0131_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0026_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0203_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0192_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0113_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0003_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0069_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0028_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0019_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0161_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0025_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0024_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0124_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0035_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0166_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0001_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0100_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0125_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0080_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0065_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0172_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0030_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0094_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0088_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0020_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0177_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0163_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0197_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0018_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0187_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0022_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0085_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0158_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0043_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0101_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0036_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0144_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0146_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0077_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0083_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0198_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0082_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0084_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0137_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0112_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0121_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0117_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0015_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0034_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0039_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0167_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0012_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0013_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0103_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0078_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0079_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0106_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0104_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0107_0002.nii.gz\",\n",
            "    \"./imagesTr/Case_0104_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0015_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0138_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0051_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0075_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0016_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0029_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0118_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0183_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0054_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0042_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0063_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0102_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0135_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0082_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0186_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0087_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0200_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0168_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0067_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0004_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0127_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0003_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0043_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0099_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0062_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0201_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0021_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0199_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0093_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0162_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0002_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0190_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0074_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0065_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0076_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0124_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0142_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0038_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0025_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0137_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0139_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0158_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0034_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0179_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0047_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0114_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0196_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0057_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0150_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0166_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0177_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0184_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0073_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0167_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0155_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0055_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0122_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0012_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0094_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0027_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0069_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0077_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0128_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0117_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0182_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0173_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0116_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0064_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0109_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0108_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0130_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0202_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0121_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0006_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0164_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0019_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0032_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0132_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0163_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0036_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0010_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0125_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0078_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0147_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0005_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0172_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0160_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0072_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0149_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0111_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0039_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0187_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0105_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0017_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0011_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0040_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0106_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0100_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0154_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0045_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0018_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0023_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0091_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0052_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0020_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0181_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0191_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0178_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0180_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0041_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0174_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0096_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0066_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0119_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0188_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0001_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0053_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0126_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0193_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0110_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0152_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0113_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0129_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0085_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0146_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0008_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0101_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0171_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0022_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0026_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0031_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0153_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0115_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0061_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0189_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0123_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0170_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0058_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0198_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0141_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0030_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0159_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0009_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0033_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0090_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0071_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0165_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0049_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0161_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0133_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0092_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0175_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0145_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0046_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0059_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0014_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0084_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0098_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0148_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0195_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0136_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0079_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0060_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0048_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0037_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0103_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0112_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0097_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0203_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0176_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0151_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0088_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0169_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0157_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0192_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0007_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0013_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0194_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0107_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0140_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0083_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0197_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0156_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0050_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0086_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0044_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0028_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0089_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0070_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0035_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0095_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0120_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0134_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0081_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0024_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0056_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0080_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0143_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0131_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0144_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0185_0003.nii.gz\",\n",
            "    \"./imagesTr/Case_0068_0003.nii.gz\"\n",
            "  ],\n",
            "  \"label\": \"./labelsTr/Case.nii.gz\"\n",
            "}\n",
            "Image field type: <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNet_plan_and_preprocess -t 1 --verify_dataset_integrity"
      ],
      "metadata": {
        "id": "Zp4634miHlrD",
        "outputId": "eb83ad8c-83b1-45ad-a4ce-e6426dbc26e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/nnUNet_plan_and_preprocess\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nnunet/experiment_planning/nnUNet_plan_and_preprocess.py\", line 105, in main\n",
            "    verify_dataset_integrity(join(nnUNet_raw_data, task_name))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nnunet/preprocessing/sanity_checks.py\", line 107, in verify_dataset_integrity\n",
            "    test_cases = dataset['test']\n",
            "                 ~~~~~~~^^^^^^^^\n",
            "KeyError: 'test'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNet_train 3d_fullres nnUNetTrainerV2 Task001_Glioma 0 --npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5YdjAFrn_af",
        "outputId": "8a4c6af9-8d76-47e3-885e-ad7a2f05fe67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/nnUNet_train\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nnunet/run/run_training.py\", line 140, in main\n",
            "    trainer_class = get_default_configuration(network, task, network_trainer, plans_identifier)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nnunet/run/default_configuration.py\", line 47, in get_default_configuration\n",
            "    plans = load_pickle(plans_file)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 92, in load_pickle\n",
            "    with open(file, mode) as f:\n",
            "         ^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/nnUNet_preprocessed/Task001_Glioma/nnUNetPlansv2.1_plans_3D.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jW_ld5jSt6Cj"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}