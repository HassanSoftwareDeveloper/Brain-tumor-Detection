{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCBwwhrKcDA3"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # LongiTumorSense Model Training\n",
        "# **Training on MU-Glioma-Post Dataset**\n",
        "# - Segmentation: nnUNet\n",
        "# - Classification: 3D DenseNet\n",
        "# - Survival: CoxPH Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai torch torchvision nnunet pyradiomics lifelines pydicom nibabel wandb -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2Uf9AEeMMcF",
        "outputId": "bfb74699-04f3-4cb8-aff1-931fdeadb22e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.3/156.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for nnunet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyradiomics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for medpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qiq-ZeBbCbIA"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import numpy  as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import os\n",
        "import monai\n",
        "from monai.data import Dataset ,DataLoader\n",
        "from monai.transforms import ( Compose , LoadImaged , EnsureChannelFirstd, ScaleIntensityd,RandRotated,RandFlipd,RandZoomd,ToTensord)\n",
        "from monai.networks.nets import DenseNet121,Unet\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss, FocalLoss\n",
        "import wandb\n",
        "import pandas as pd\n",
        "from lifelines import CoxPHFitter\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "1C4DKCohFTg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTTpC4VwC0Do",
        "outputId": "85e1e2bf-ee5a-46ff-a530-6bf8d58c3577"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device.\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\"\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\"\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "print(f\"Using {device} device.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2YW8EoXMYN2",
        "outputId": "3f064ff3-afdd-4e9e-f3e4-8bd27b63bd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Clearner and saved into the drive**"
      ],
      "metadata": {
        "id": "Ri04EaJBM6Oh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8OKuE6ycWJn",
        "outputId": "9f1461b1-92f9-416a-ef60-1817652f4915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw dataset path: /content/drive/My Drive/MU-Glioma-Post\n",
            "nnU-Net dataset path: /content/drive/My Drive/clean_data\n",
            "Found 4 cases already processed.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "raw_root = \"/content/drive/My Drive/MU-Glioma-Post\"\n",
        "\n",
        "output_root=\"/content/drive/My Drive/clean_data\"\n",
        "\n",
        "\n",
        "\n",
        "imagesTr = os.path.join(output_root, \"imagesTr\")\n",
        "labelsTr = os.path.join(output_root, \"labelsTr\")\n",
        "os.makedirs(os.path.join(output_root, \"imagesTs\"), exist_ok=True)\n",
        "os.makedirs(imagesTr, exist_ok=True)\n",
        "os.makedirs(labelsTr, exist_ok=True)\n",
        "\n",
        "print(\"Raw dataset path:\", raw_root)\n",
        "print(\"nnU-Net dataset path:\", output_root)\n",
        "\n",
        "\n",
        "progress_file = os.path.join(output_root, \"converted_cases.txt\")\n",
        "\n",
        "if os.path.exists(progress_file):\n",
        "    with open(progress_file, \"r\") as f:\n",
        "        converted_cases = set(line.strip() for line in f)\n",
        "else:\n",
        "    converted_cases = set()\n",
        "print(f\"Found {len(converted_cases)} cases already processed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqpZTvVpf7mf"
      },
      "outputs": [],
      "source": [
        "def is_nifti(fname):\n",
        "  return fname.endswith(\".nii\") or fname.endswith(\".nii.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYZeKxppgCo3"
      },
      "outputs": [],
      "source": [
        "mod_priority=[\n",
        "      't1c','t1gd','t1ce',  # contrast-enhanced T1 variants\n",
        "    't1n','t1',           # native T1\n",
        "    'flair','t2f','t2flair','t2w','t2' # T2 /flair variants\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Iev103XgQPf"
      },
      "outputs": [],
      "source": [
        "def file_priority(fname):\n",
        "  lf=fname.lower()\n",
        "  for i,k in enumerate(mod_priority):\n",
        "    if k in lf:\n",
        "      return i\n",
        "  return len(mod_priority) + hash(lf) % 1000"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "canonical_modalities = None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "skipped = []\n",
        "new_cases_count = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "total_timepoints = sum(\n",
        "    1 for p in sorted(os.listdir(raw_root))\n",
        "    if os.path.isdir(os.path.join(raw_root, p))\n",
        "    for tp in sorted(os.listdir(os.path.join(raw_root, p)))\n",
        "    if os.path.isdir(os.path.join(raw_root, p, tp))\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with tqdm(total=total_timepoints, desc=\"Processing cases\") as pbar:\n",
        "    for patient_id in sorted(os.listdir(raw_root)):\n",
        "        patient_path = os.path.join(raw_root, patient_id)\n",
        "        if not os.path.isdir(patient_path):\n",
        "            pbar.update(1)\n",
        "            continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for tp in sorted(os.listdir(patient_path)):\n",
        "            tp_path = os.path.join(patient_path, tp)\n",
        "            if not os.path.isdir(tp_path):\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "            tp_clean = re.sub(r\"\\s+\", \"_\", tp)\n",
        "            tp_clean = re.sub(r\"[^A-Za-z0-9_-]\", \"_\", tp_clean)\n",
        "            case_id = f\"{patient_id}_{tp_clean}\"\n",
        "\n",
        "\n",
        "\n",
        "            if case_id in converted_cases:\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "            files = [f for f in os.listdir(tp_path) if is_nifti(f)]\n",
        "            if not files:\n",
        "                skipped.append((patient_id, tp, \"no nifti files\"))\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "            label_candidates = [f for f in files if any(x in f.lower() for x in [\"mask\", \"tumor\", \"seg\", \"label\"])]\n",
        "            if len(label_candidates) == 0:\n",
        "                skipped.append((patient_id, tp, \"no label found\"))\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "            label_file = label_candidates[0]\n",
        "\n",
        "\n",
        "\n",
        "            image_files = [f for f in files if f != label_file]\n",
        "            if len(image_files) == 0:\n",
        "                skipped.append((patient_id, tp, \"no image files\"))\n",
        "                pbar.update(1)\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "            image_files_sorted = sorted(image_files, key=file_priority)\n",
        "            if canonical_modalities is None:\n",
        "                canonical_modalities = image_files_sorted.copy()\n",
        "                print(\"\\nDetected modality order (from first sample)\")\n",
        "                for idx, nm in enumerate(canonical_modalities):\n",
        "                    print(f\"{idx}: {nm}\")\n",
        "                print(\"If this order is wrong adjust mod_priority list in the script.\")\n",
        "\n",
        "\n",
        "            else:\n",
        "                if len(image_files_sorted) != len(canonical_modalities):\n",
        "                    skipped.append(\n",
        "                        (patient_id, tp, f\"modality count mismatch {len(image_files_sorted)} vs {len(canonical_modalities)}\")\n",
        "                    )\n",
        "                    pbar.update(1)\n",
        "                    continue\n",
        "\n",
        "\n",
        "\n",
        "            for i, fname in enumerate(image_files_sorted):\n",
        "                src = os.path.join(tp_path, fname)\n",
        "                destination = os.path.join(imagesTr, f\"{case_id}_{i:04d}.nii.gz\")\n",
        "                shutil.copy(src, destination)\n",
        "\n",
        "            shutil.copy2(os.path.join(tp_path, label_file), os.path.join(labelsTr, f\"{case_id}.nii.gz\"))\n",
        "\n",
        "\n",
        "\n",
        "            converted_cases.add(case_id)\n",
        "            with open(progress_file, \"a\") as f:\n",
        "                f.write(case_id + \"\\n\")\n",
        "\n",
        "            new_cases_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "print(f\"\\nConversion finished. {len(converted_cases)} total cases processed so far.\")\n",
        "if skipped:\n",
        "    print(f\"{len(skipped)} timepoints skipped (see sample):\")\n",
        "    for s in skipped[:10]:\n",
        "        print(\" \", s)\n",
        "\n",
        "print(f\"imagesTr files: {len(os.listdir(imagesTr))}, labelsTr files: {len(os.listdir(labelsTr))}\")\n",
        "print(f\"Newly processed this run: {new_cases_count}\")"
      ],
      "metadata": {
        "id": "0n_o0C16-mDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get clean data from drive into local colab for further processing**"
      ],
      "metadata": {
        "id": "YyI_fuYGDqA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "drive_clean_path = \"/content/drive/MyDrive/clean_data\"\n",
        "local_clean_path = \"/content/clean_data_local\"\n",
        "\n",
        "os.makedirs(local_clean_path,exist_ok=True)\n",
        "\n",
        "\n",
        "all_files=[]\n",
        "\n",
        "for root,dirs,files in os.walk(drive_clean_path):\n",
        "    for file in files:\n",
        "      source_file=os.path.join(root,file)\n",
        "      relative_path=os.path.relpath(source_file,drive_clean_path)\n",
        "      destination_file=os.path.join(local_clean_path,relative_path)\n",
        "      all_files.append((source_file, destination_file))\n",
        "\n",
        "\n",
        "remaining_files=[]\n",
        "for source_file,destination_file in all_files:\n",
        "    if os.path.exists(destination_file)and os.path.getsize(destination_file)==os.path.getsize(source_file):\n",
        "       continue\n",
        "    remaining_files.append((source_file,destination_file))\n",
        "\n",
        "for source_file,destination_file in tqdm(remaining_files, desc=\"copying files\", unit=\"files\"):\n",
        "    os.makedirs(os.path.dirname(destination_file),exist_ok=True)\n",
        "    shutil.copy2(source_file , destination_file)\n",
        "\n",
        "print(f\"copy complete!{len(all_files)-len(remaining_files)} files already exists,{len(remaining_files)} new files copied\")\n",
        "print(\" Clean dataset loaded from Drive.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8mxhBhBAW6h",
        "outputId": "ec5650bb-21c3-4adb-c06c-f8e591cf4e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "copying files: 100%|██████████| 2972/2972 [13:06<00:00,  3.78files/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "copy complete!0 files already exists,2972 new files copied\n",
            " Clean dataset loaded from Drive.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This is for checking the length of file for each imageTr and labelTr**"
      ],
      "metadata": {
        "id": "rGGZ6yiKMurh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imagesTr_path=os.path.join(local_clean_path,\"imagesTr\")\n",
        "labelsTr_path=os.path.join(local_clean_path,\"labelsTr\")\n",
        "\n",
        "length_imageTr=len([f for f in os.listdir(imagesTr_path) if os.path.isfile(os.path.join(imagesTr_path,f))])\n",
        "length_labelsTr=len([f for f in os.listdir(labelsTr_path) if os.path.isfile(os.path.join(labelsTr_path,f))])\n",
        "\n",
        "print(f\" imageTr files:{length_imageTr}\")\n",
        "print(f\" labelsTr files:{length_labelsTr}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSbJP58r7tKT",
        "outputId": "34408c8e-bc88-4089-d656-5bc737e0fc49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " imageTr files:2376\n",
            " labelsTr files:594\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiegR9RiCE9l"
      },
      "source": [
        "**After Disconnect:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IGS3nUAZ22D0"
      },
      "outputs": [],
      "source": [
        "!pip install monai torch torchvision nnunet pyradiomics lifelines pydicom nibabel wandb -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxdV-3ovAz3h"
      },
      "source": [
        "**Install a Python package directly from its GitHub source code, not from the normal package store (PyPI).”**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEzaBMYLCTVI"
      },
      "source": [
        "**This function loads an MRI file, converts it to a NumPy array, and scales all values to between 0 and 1 for easier analysis.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/MIC-DKFZ/nnUNet.git"
      ],
      "metadata": {
        "id": "PVPVEKZjQjV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YOcMNyv3YC7"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr2v-669CSwg"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import numpy  as np\n",
        "\n",
        "def load_and_preprocess(patient_path):\n",
        "    img = nib.load(patient_path)\n",
        "    data = img.get_fdata()\n",
        "    data = (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-mzSkdJPP36u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Renames the file into nnuNet naming style**\n",
        "\n",
        "**Copy and rename image files**\n",
        "\n",
        "**Copy and rename label files**\n"
      ],
      "metadata": {
        "id": "RrALGUyCQ8O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import shutil\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "source_images = \"/content/drive/MyDrive/clean_data/imagesTr\"\n",
        "source_labels = \"/content/drive/MyDrive/clean_data/labelsTr\"\n",
        "\n",
        "destination_imagesTr = \"/content/clean_data_local/imagesTr\"\n",
        "destination_labelsTr = \"/content/clean_data_local/labelsTr\"\n",
        "\n",
        "os.makedirs(destination_imagesTr, exist_ok=True)\n",
        "os.makedirs(destination_labelsTr, exist_ok=True)\n",
        "\n",
        "image_files = glob(os.path.join(source_images, \"*.nii.gz\"))\n",
        "label_files = glob(os.path.join(source_labels, \"*.nii.gz\"))\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Copying {len(image_files)} image files...\")\n",
        "\n",
        "\n",
        "for scan_path in tqdm(image_files, desc=\"Images copied\", unit=\"file\"):\n",
        "    filename = os.path.basename(scan_path)\n",
        "    match = re.match(r\"(PatientID_\\d+)_Timepoint_(\\d+)_(\\d{4})\\.nii\\.gz\", filename)\n",
        "    if match:\n",
        "        patient_id, timepoint, modality_idx = match.groups()\n",
        "        case_id = f\"{patient_id}_Timepoint_{timepoint}\"\n",
        "        destination_path = os.path.join(destination_imagesTr, f\"{case_id}_{modality_idx}.nii.gz\")\n",
        "        if scan_path != destination_path:\n",
        "            shutil.copy(scan_path, destination_path)\n",
        "\n",
        "print(f\"Copying {len(label_files)} label files...\")\n",
        "\n",
        "\n",
        "for label_path in tqdm(label_files, desc=\"Labels copied\", unit=\"file\"):\n",
        "    filename = os.path.basename(label_path)\n",
        "    match = re.match(r\"(PatientID_\\d+)_Timepoint_(\\d+)\\.nii\\.gz\", filename)\n",
        "    if match:\n",
        "        patient_id, timepoint = match.groups()\n",
        "        case_id = f\"{patient_id}_Timepoint_{timepoint}\"\n",
        "        dst_path = os.path.join(destination_labelsTr, f\"{case_id}.nii.gz\")\n",
        "        if label_path != dst_path:\n",
        "            shutil.copy(label_path, dst_path)\n",
        "\n",
        "print(f\"Total copied {len(os.listdir(destination_imagesTr))} scans to {destination_imagesTr}\")\n",
        "print(f\"Total copied {len(os.listdir(destination_labelsTr))} labels to {destination_labelsTr}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ExmO0wKU5I1",
        "outputId": "4c661566-8a3e-40a4-9b28-f9e3bcd3bd76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying 2376 image files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Images copied: 100%|██████████| 2376/2376 [06:36<00:00,  6.00file/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying 594 label files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Labels copied: 100%|██████████| 594/594 [02:21<00:00,  4.19file/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total copied 2376 scans to /content/clean_data_local/imagesTr\n",
            "Total copied 594 labels to /content/clean_data_local/labelsTr\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imagesTr_path = \"/content/clean_data_local/imagesTr\"\n",
        "labelsTr_path = \"/content/clean_data_local/labelsTr\"\n",
        "\n",
        "\n",
        "def clean_zero_byte_files(folder_path):\n",
        "     deleted_files=[]\n",
        "     for root,_, files in os.walk(folder_path):\n",
        "         for file in files:\n",
        "             file_path=os.path.join(root,file)\n",
        "             if os.path.getsize(file_path)==0:\n",
        "                print(f\"Deleting 0-byte file : {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                deleted_files.append(file_path)\n",
        "     return deleted_files# Clean both images and labels\n",
        "deleted_images = clean_zero_byte_files(imagesTr_path)\n",
        "deleted_labels = clean_zero_byte_files(labelsTr_path)\n",
        "\n",
        "print(f\"\\nDeleted {len(deleted_images)} image files and {len(deleted_labels)} label files.\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2w42vLvcG3g",
        "outputId": "af6dd6cf-18a4-4aea-ab23-2a38d41119c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Deleted 0 image files and 0 label files.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_path = \"/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0001.nii.gz\"\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    if os.path.getsize(file_path) == 0:\n",
        "        os.remove(file_path)\n",
        "        print(\"Deleted 0-byte file:\", file_path)\n",
        "    else:\n",
        "        print(\"File is not empty, skipping deletion.\")\n",
        "else:\n",
        "    print(\"File not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYA1ixO5YK0l",
        "outputId": "446fe2e5-02ea-4e12-a2d3-b3995fd8b9a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This code creates a dataset.json file that describes your medical imaging dataset for nnU-Net.**"
      ],
      "metadata": {
        "id": "2SqZer9eXjVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from collections import defaultdict\n",
        "output_root = \"/content/clean_data_local/nnUNet_raw_data/nnUNet_raw_data/Task001_Glioma/\"\n",
        "def create_nnunet_dataset_json(output_root, task_name=\"Task001_Glioma\"):\n",
        "    \"\"\"\n",
        "    Creates a 100% nnUNet-compliant dataset.json with:\n",
        "    - Automatic test set detection\n",
        "    - Better error handling\n",
        "    - Enhanced validation\n",
        "    - Colab-friendly output\n",
        "    \"\"\"\n",
        "\n",
        "    imagesTr_path = os.path.join(output_root, \"imagesTr\")\n",
        "    labelsTr_path = os.path.join(output_root, \"labelsTr\")\n",
        "    imagesTs_path = os.path.join(output_root, \"imagesTs\")\n",
        "\n",
        "\n",
        "    os.makedirs(imagesTr_path, exist_ok=True)\n",
        "    os.makedirs(labelsTr_path, exist_ok=True)\n",
        "    os.makedirs(imagesTs_path, exist_ok=True)\n",
        "\n",
        "\n",
        "    try:\n",
        "        case_ids = sorted([f.split('.nii.gz')[0] for f in os.listdir(labelsTr_path)\n",
        "                      if f.endswith('.nii.gz')])\n",
        "        if not case_ids:\n",
        "            raise ValueError(\" No label files found in labelsTr! Add your segmentation masks.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading labels: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    try:\n",
        "        sample_case = case_ids[0]\n",
        "        sample_files = [f for f in os.listdir(imagesTr_path) if sample_case in f]\n",
        "        if not sample_files:\n",
        "            raise ValueError(f\"No matching images found for sample case {sample_case}\")\n",
        "\n",
        "        all_modalities = sorted(list(set(\n",
        "            re.search(r'_(\\d{4})\\.nii\\.gz$', f).group(1)\n",
        "            for f in sample_files\n",
        "            if re.search(r'_(\\d{4})\\.nii\\.gz$', f)\n",
        "        )))\n",
        "        if not all_modalities:\n",
        "            raise ValueError(\"Could not detect modality patterns in image filenames\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error detecting modalities: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    training = []\n",
        "    missing_modalities = defaultdict(int)\n",
        "\n",
        "    for case_id in case_ids:\n",
        "        case_files = [f for f in os.listdir(imagesTr_path) if case_id in f]\n",
        "        available_mods = set(\n",
        "            re.search(r'_(\\d{4})\\.nii\\.gz$', f).group(1)\n",
        "            for f in case_files\n",
        "            if re.search(r'_(\\d{4})\\.nii\\.gz$', f)\n",
        "        )\n",
        "\n",
        "        for mod in all_modalities:\n",
        "            if mod in available_mods:\n",
        "                training.append({\n",
        "                    \"image\": f\"./imagesTr/{case_id}_{mod}.nii.gz\",\n",
        "                    \"label\": f\"./labelsTr/{case_id}.nii.gz\"\n",
        "                })\n",
        "            else:\n",
        "                missing_modalities[mod] += 1\n",
        "\n",
        "\n",
        "    test = []\n",
        "    if os.path.exists(imagesTs_path) and os.listdir(imagesTs_path):\n",
        "        test_files = [f for f in os.listdir(imagesTs_path) if f.endswith('.nii.gz')]\n",
        "        test = [f\"./imagesTs/{f}\" for f in test_files]\n",
        "\n",
        "\n",
        "    dataset_json = {\n",
        "        \"name\": task_name.split('_', 1)[-1],\n",
        "        \"description\": \"Glioma segmentation dataset\",\n",
        "        \"reference\": \"Your reference\",\n",
        "        \"licence\": \"Your license\",\n",
        "        \"release\": \"1.0\",\n",
        "        \"modality\": {str(i): f\"modality_{mod}\" for i, mod in enumerate(all_modalities)},\n",
        "        \"labels\": {\n",
        "            \"0\": \"background\",\n",
        "            \"1\": \"tumor\",\n",
        "\n",
        "        },\n",
        "        \"numTraining\": len(case_ids),\n",
        "        \"file_ending\": \".nii.gz\",\n",
        "        \"training\": training,\n",
        "        \"test\": test\n",
        "    }\n",
        "\n",
        "\n",
        "    output_path = os.path.join(output_root, \"dataset.json\")\n",
        "    try:\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(dataset_json, f, indent=4)\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving dataset.json: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    print(\"\\n Successfully created nnUNet-compliant dataset.json\")\n",
        "    print(\" Dataset Summary:\")\n",
        "    print(f\"   - Task Name: {task_name}\")\n",
        "    print(f\"   - Training Cases: {len(case_ids)}\")\n",
        "    print(f\"   - Modalities: {len(all_modalities)} ({', '.join(all_modalities)})\")\n",
        "    print(f\"   - Training Entries: {len(training)}\")\n",
        "    print(f\"   - Test Cases: {len(test)}\")\n",
        "\n",
        "    if missing_modalities:\n",
        "        print(\"\\n  Missing Modalities Report:\")\n",
        "        for mod, count in missing_modalities.items():\n",
        "            print(f\"   - Modality {mod} missing in {count}/{len(case_ids)} cases\")\n",
        "\n",
        "    print(f\"\\nSaved to: {output_path}\")\n",
        "    print(\"\\n Verification Command:\")\n",
        "    print(f\"!nnUNet_verify_dataset -t {task_name.split('_')[0][4:]}\")\n",
        "\n",
        "    return output_path\n"
      ],
      "metadata": {
        "id": "KOOC9Z72CDhM"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_nnunet_dataset_json(\n",
        "    output_root=\"/content/clean_data_local/nnUNet_raw_data/nnUNet_raw_data/Task001_Glioma\",\n",
        "    task_name=\"Task001_Glioma\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "U7kfjcLZ_zzU",
        "outputId": "31875e9d-eb83-4b60-de44-26a0d5be9fd9"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Successfully created nnUNet-compliant dataset.json\n",
            " Dataset Summary:\n",
            "   - Task Name: Task001_Glioma\n",
            "   - Training Cases: 593\n",
            "   - Modalities: 4 (0000, 0001, 0002, 0003)\n",
            "   - Training Entries: 2371\n",
            "   - Test Cases: 0\n",
            "\n",
            "  Missing Modalities Report:\n",
            "   - Modality 0001 missing in 1/593 cases\n",
            "\n",
            "Saved to: /content/clean_data_local/nnUNet_raw_data/nnUNet_raw_data/Task001_Glioma/dataset.json\n",
            "\n",
            " Verification Command:\n",
            "!nnUNet_verify_dataset -t 001\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/clean_data_local/nnUNet_raw_data/nnUNet_raw_data/Task001_Glioma/dataset.json'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkjWjNWHBBdW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "# Print your default W&B username (entity)\n",
        "print(\"Your W&B username:\", wandb.Api().default_entity)\n",
        "\n",
        "# Alternative: Check after login\n",
        "wandb.login()\n",
        "print(\"Logged in as:\", wandb.Api().default_entity)"
      ],
      "metadata": {
        "id": "VRxzFScnoqqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"LongiTumorSense\",entity=\"numl-f21-35629-numl\")"
      ],
      "metadata": {
        "id": "vJa0eTVtEgpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def prepare_dataset(imagesTr, labelsTr, test_size=0.2):\n",
        "\n",
        "    image_files = [f for f in os.listdir(imagesTr) if f.endswith(\".nii.gz\")]\n",
        "    case_ids = sorted(list(set(\"_\".join(f.split(\"_\")[:-1]) for f in image_files)))\n",
        "\n",
        "    print(f\"Found {len(case_ids)} unique cases.\")\n",
        "\n",
        "    # Split into train and test\n",
        "    train_cases, test_cases = train_test_split(case_ids, test_size=test_size, random_state=42)\n",
        "\n",
        "    missing_labels = []\n",
        "\n",
        "    def build_file_list(cases):\n",
        "        file_list = []\n",
        "        for case_id in cases:\n",
        "            # Build list of all 4 modalities for this case\n",
        "            modalities = [\n",
        "                os.path.join(imagesTr, f\"{case_id}_0000.nii.gz\"),  # FLAIR\n",
        "                os.path.join(imagesTr, f\"{case_id}_0001.nii.gz\"),  # T1\n",
        "                os.path.join(imagesTr, f\"{case_id}_0002.nii.gz\"),  # T1ce\n",
        "                os.path.join(imagesTr, f\"{case_id}_0003.nii.gz\")   # T2\n",
        "            ]\n",
        "            label_path = os.path.join(labelsTr, f\"{case_id}.nii.gz\")\n",
        "\n",
        "            if not os.path.exists(label_path):\n",
        "                missing_labels.append(case_id)\n",
        "                continue\n",
        "\n",
        "            file_list.append({\n",
        "                \"image\": modalities,\n",
        "                \"label\": label_path,\n",
        "                \"name\": case_id\n",
        "            })\n",
        "        return file_list\n",
        "\n",
        "    train_files = build_file_list(train_cases)\n",
        "    test_files = build_file_list(test_cases)\n",
        "\n",
        "    print(f\"Length of training dataset: {len(train_files)}\")\n",
        "    print(f\"Length of validation dataset: {len(test_files)}\")\n",
        "\n",
        "    if missing_labels:\n",
        "        print(f\"Missing labels for {len(missing_labels)} cases: {missing_labels[:10]}{'...' if len(missing_labels) > 10 else ''}\")\n",
        "\n",
        "    return train_files, test_files\n"
      ],
      "metadata": {
        "id": "J7q_yUWaiEj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_files, test_files = prepare_dataset(\n",
        "    \"/content/clean_data_local/imagesTr\",\n",
        "    \"/content/clean_data_local/labelsTr\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bd4Qh8G7Z7Us",
        "outputId": "79b869fb-0d1d-4f0e-af0a-16aadf361893"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 594 unique cases.\n",
            "Length of training dataset: 474\n",
            "Length of validation dataset: 119\n",
            "Missing labels for 1 cases: ['PatientID_0275_Timepoint_6']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwp0vLhAMGLZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**this is used for skipped bad , unreachable ,missing samples instead of crashing**"
      ],
      "metadata": {
        "id": "GkxhivpdbilD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import LoadImaged\n",
        "from monai.data import Dataset as MonaiDataset,DataLoader\n",
        "class SafeDataset(MonaiDataset):\n",
        "    def __getitem__(self, index):\n",
        "        item = self.data[index]\n",
        "        try:\n",
        "            if self.transform is not None:\n",
        "                transformed_item = self.transform(item)\n",
        "                if transformed_item is not None:\n",
        "                    return transformed_item\n",
        "                else:\n",
        "                    image=item.get(\"image\",\"unknown\")\n",
        "                    print(f\"Skipping sample at index: {index}:{image} (Transform returned None)\")\n",
        "                    return None\n",
        "\n",
        "            return item\n",
        "\n",
        "        except (FileNotFoundError, nib.filebasedimages.ImageFileError, RuntimeError)  as e:\n",
        "              image=item.get(\"image\",\"unknown\")\n",
        "              print(f\"Skipping sample at index: {index}:{image} ({e})\")\n",
        "              return None\n",
        "        except Exception as e:\n",
        "             image= item.get(\"image\",\"unknown\")\n",
        "             print(f\"Skipping sample at index:  {index} due to unexpected error: {image} ({e})\")\n",
        "             return None"
      ],
      "metadata": {
        "id": "nlhNxvRsmRi9"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**t checks the batch list, kicks out the None entries, and only lets valid data into the collate party. **"
      ],
      "metadata": {
        "id": "CZIdBJt_b_KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data._utils.collate import default_collate\n",
        "def collate_skip_none(batch):\n",
        "    batch = [item for item in batch if item is not None]\n",
        "    if not batch:\n",
        "        return []\n",
        "    return default_collate(batch)"
      ],
      "metadata": {
        "id": "kXEDwad90kO8"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load images → put channel first → convert to PyTorch tensor.**"
      ],
      "metadata": {
        "id": "QZvUMnC8cglB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import Compose\n",
        "\n",
        "transform_basic=Compose([\n",
        "    LoadImaged(keys=[\"image\"],allow_missing_keys=True),\n",
        "    EnsureChannelFirstd(keys=[\"image\"]),\n",
        "    ToTensord(keys=[\"image\"])\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "n5kxY5IhcMTj"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=4\n",
        "train_dataset_basic=SafeDataset(data=train_files,transform=transform_basic)\n",
        "train_loader_basic=DataLoader(train_dataset_basic,batch_size=batch_size, collate_fn=collate_skip_none, shuffle=True)\n",
        "batch_shape=next(iter(train_loader_basic))[\"image\"].shape\n",
        "print(\"Getting batches of shape:\",batch_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poHP67I9fkf1",
        "outputId": "2fada7dc-6d0c-4f66-a2b9-36d6e683e3d5"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting batches of shape: torch.Size([4, 4, 240, 240, 155])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**check original file in drive**"
      ],
      "metadata": {
        "id": "BIrjIItcWGu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def get_mean_std(dataset_loader_basic, resume_file=None, nonzero=True):\n",
        "    \"\"\"\n",
        "    Compute per-channel mean and std from a DataLoader that yields dicts with key 'image'.\n",
        "\n",
        "    Args:\n",
        "        dataset_loader_basic: PyTorch DataLoader returning batches with [\"image\"] tensors\n",
        "                              of shape [B, C, H, W] or [B, C, D, H, W]\n",
        "        resume_file (str or None): Optional file to store the last processed batch index for resuming.\n",
        "        nonzero (bool): If True, compute statistics only over nonzero voxels (ignores background).\n",
        "\n",
        "    Returns:\n",
        "        mean (torch.Tensor): Per-channel mean values.\n",
        "        std (torch.Tensor): Per-channel standard deviations.\n",
        "    \"\"\"\n",
        "    start_index = 0\n",
        "    if resume_file is not None and os.path.exists(resume_file):\n",
        "        with open(resume_file, \"r\") as f:\n",
        "            start_index = int(f.read().strip() or 0)\n",
        "        print(f\"Resuming from batch index {start_index}...\")\n",
        "\n",
        "    first_batch = next(iter(dataset_loader_basic))\n",
        "    num_channels = first_batch[\"image\"].shape[1]\n",
        "\n",
        "    if nonzero:\n",
        "        channels_sum = torch.zeros(num_channels)\n",
        "        channels_squared_sum = torch.zeros(num_channels)\n",
        "        voxel_counts = torch.zeros(num_channels)\n",
        "    else:\n",
        "        channels_sum = torch.zeros(num_channels)\n",
        "        channels_squared_sum = torch.zeros(num_channels)\n",
        "        num_batches = 0\n",
        "\n",
        "    for idx, batch in enumerate(tqdm(dataset_loader_basic, desc=\"Computing mean/std\", unit=\"batch\")):\n",
        "        if idx < start_index:\n",
        "            continue\n",
        "        try:\n",
        "            data = batch[\"image\"].float()\n",
        "\n",
        "            if nonzero:\n",
        "                for c in range(num_channels):\n",
        "                    mask = data[:, c] != 0\n",
        "                    vals = data[:, c][mask]\n",
        "                    if vals.numel() > 0:\n",
        "                        channels_sum[c] += vals.sum()\n",
        "                        channels_squared_sum[c] += (vals ** 2).sum()\n",
        "                        voxel_counts[c] += vals.numel()\n",
        "            else:\n",
        "                dims = list(range(0, data.ndim))\n",
        "                dims.remove(1)\n",
        "                channels_sum += data.mean(dim=dims)\n",
        "                channels_squared_sum += (data ** 2).mean(dim=dims)\n",
        "                num_batches += 1\n",
        "\n",
        "            if resume_file is not None:\n",
        "                with open(resume_file, \"w\") as f:\n",
        "                    f.write(str(idx + 1))\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch {idx}: {e}\")\n",
        "\n",
        "    if nonzero:\n",
        "        if (voxel_counts == 0).any():\n",
        "            raise ValueError(\"Some channels have no nonzero voxels.\")\n",
        "        mean = channels_sum / voxel_counts\n",
        "        std = torch.sqrt(channels_squared_sum / voxel_counts - mean ** 2)\n",
        "    else:\n",
        "        if num_batches == 0:\n",
        "            raise ValueError(\"No valid images found in the dataset.\")\n",
        "        mean = channels_sum / num_batches\n",
        "        std = torch.sqrt(channels_squared_sum / num_batches - mean ** 2)\n",
        "\n",
        "    return mean, std\n"
      ],
      "metadata": {
        "id": "N_3kL5bhKu9N"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mean, std = get_mean_std(train_loader_basic,resume_file=None)\n",
        "print(\"Mean:\", mean)\n",
        "print(\"Std:\", std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2GfSZ_gcz3A",
        "outputId": "8d9c42cb-9bdf-4ea8-e5b4-6f096b1d564a"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std:  66%|██████▋   | 79/119 [08:13<04:14,  6.36s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping sample at index: 261:['/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0000.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0001.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0002.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0003.nii.gz'] (applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7a4f006b15d0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std: 100%|██████████| 119/119 [12:22<00:00,  6.24s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor([305.7782, 271.5573, 247.0512, 447.8155])\n",
            "Std: tensor([218.4011, 160.3656, 143.3827, 233.6108])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {
        "id": "2M4QzyL6WNaf"
      },
      "outputs": [],
      "source": [
        "from monai.transforms import Compose, LoadImaged, EnsureChannelFirstd, ScaleIntensityd, NormalizeIntensityd, RandRotated, RandFlipd, RandZoomd, ToTensord\n",
        "\n",
        "train_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    # ScaleIntensityd(keys=[\"image\"]),\n",
        "    NormalizeIntensityd(\n",
        "        keys=[\"image\"],\n",
        "        subtrahend=mean.tolist(),\n",
        "        divisor=std.tolist(),\n",
        "        channel_wise=True,\n",
        "        nonzero=True\n",
        "    ),\n",
        "    RandRotated(keys=[\"image\", \"label\"], range_x=0.3, prob=0.5),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5),\n",
        "    RandZoomd(keys=[\"image\", \"label\"], min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
        "    ToTensord(keys=[\"image\", \"label\"]),\n",
        "])\n",
        "\n",
        "test_transforms = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "    # ScaleIntensityd(keys=[\"image\"]),\n",
        "    NormalizeIntensityd(\n",
        "        keys=[\"image\"],\n",
        "        subtrahend=mean.tolist(),\n",
        "        divisor=std.tolist(),\n",
        "        channel_wise=True,\n",
        "        nonzero=True\n",
        "    ),\n",
        "    ToTensord(keys=[\"image\", \"label\"]),\n",
        "])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 190,
      "metadata": {
        "id": "fuEVd74Ei12y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0703d148-232c-47b7-a2c7-6f14e3e8fd96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting batches of shape: torch.Size([4, 4, 240, 240, 155])\n"
          ]
        }
      ],
      "source": [
        "batch_size=4\n",
        "train_dataset_norm =SafeDataset(data=train_files,transform=train_transforms)\n",
        "dataset_loader_norm=DataLoader(train_dataset_norm,batch_size=batch_size, collate_fn=collate_skip_none)\n",
        "batch = next(iter(dataset_loader_norm))\n",
        "if batch:\n",
        "    batch_shape=batch[\"image\"].shape\n",
        "    print(\"Getting batches of shape:\",batch_shape)\n",
        "else:\n",
        "    print(\"No valid batches were loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "norm_mean, norm_std = get_mean_std(dataset_loader_norm,resume_file=None)\n",
        "\n",
        "print(f\"Mean: {norm_mean}\")\n",
        "print(f\"Standard deviation: {norm_std}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buTOcL_VoA5L",
        "outputId": "0ed66456-bb79-46b3-d082-d73403c73009"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std:  55%|█████▍    | 65/119 [22:13<17:56, 19.93s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping sample at index: 261:['/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0000.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0001.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0002.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0021_Timepoint_6_0003.nii.gz'] (applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7a4f004a7cd0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std: 100%|██████████| 119/119 [39:41<00:00, 20.01s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor([0.0047, 0.0046, 0.0091, 0.0047])\n",
            "Standard deviation: tensor([0.9846, 0.9852, 0.9753, 0.9688])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=2\n",
        "test_dataset_norm=SafeDataset(data=test_files,transform=test_transforms)\n",
        "dataset_loader_test_norm=DataLoader(test_dataset_norm,batch_size=batch_size,collate_fn=collate_skip_none,shuffle=False)\n",
        "batch_shape=next(iter(dataset_loader_test_norm))[\"image\"].shape\n",
        "print(\"Getting batches of shape:\",batch_shape)\n",
        "print(type(test_dataset_norm))"
      ],
      "metadata": {
        "id": "eLGMPnPI98yM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786a588b-dddd-4cf1-a570-69481c86a5d6"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting batches of shape: torch.Size([2, 4, 240, 240, 155])\n",
            "<class '__main__.SafeDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "norm_mean, norm_std = get_mean_std(dataset_loader_test_norm)\n",
        "\n",
        "print(f\"Mean: {norm_mean}\")\n",
        "print(f\"Standard deviation: {norm_std}\")"
      ],
      "metadata": {
        "id": "FtlKOJq3-spn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e664219-9ece-4aa8-f4ab-8aa0086ee19d"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std:  90%|█████████ | 54/60 [03:36<00:22,  3.71s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping sample at index: 109:['/content/clean_data_local/imagesTr/PatientID_0006_Timepoint_6_0000.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0006_Timepoint_6_0001.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0006_Timepoint_6_0002.nii.gz', '/content/clean_data_local/imagesTr/PatientID_0006_Timepoint_6_0003.nii.gz'] (applying transform <monai.transforms.io.dictionary.LoadImaged object at 0x7a4f006a8690>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Computing mean/std: 100%|██████████| 60/60 [03:58<00:00,  3.97s/batch]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor([0.2668, 0.2856, 0.2744, 0.2978])\n",
            "Standard deviation: tensor([0.8363, 0.7954, 0.8210, 0.8185])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Ws6BPrPaaoe",
        "outputId": "d27d0928-de01-4bc7-9e0c-e462a7994572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'monai.data.dataloader.DataLoader'>\n",
            "<class 'monai.data.dataloader.DataLoader'>\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(type(dataset_loader_norm))\n",
        "print(type(dataset_loader_test_norm))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "length_dataset = len(train_dataset_norm)\n",
        "length_train = int(length_dataset * 0.8)\n",
        "length_remaining = length_dataset - length_train\n",
        "train_subset, remaining_subset = random_split(train_dataset_norm, [length_train, length_remaining])\n",
        "\n",
        "percent_train = np.round(100 * len(train_subset) / length_dataset, 2)\n",
        "\n",
        "print(f\"Train data is {percent_train}% of full data\")"
      ],
      "metadata": {
        "id": "GMUlwK41CwhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee5b20aa-9e75-425d-8fff-716a25070bc3"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data is 79.96% of full data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "length_dataset_test = len(test_dataset_norm)\n",
        "length_test = int(length_dataset_test * 0.2)\n",
        "length_remaining_test = length_dataset_test - length_test\n",
        "\n",
        "test_subset, remaining_subset_test = random_split(test_dataset_norm, [length_test, length_remaining_test])\n",
        "\n",
        "percent_test = np.round(100 * len(test_subset) / length_dataset_test, 2)\n",
        "\n",
        "print(f\"Test data is {percent_test}% of full test data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msnun4bFzaOs",
        "outputId": "a335a79f-92d4-4549-b7f1-090a3579e5bc"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test data is 19.33% of full test data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4zGBucN1xZ_"
      },
      "source": [
        "\n",
        "**# Convert dataset to nnUNet format**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['nnUNet_raw_data_base'] = '/content/clean_data_local/nnUNet_raw_data'\n",
        "os.environ['nnUNet_preprocessed'] = '/content/nnUNet_preprocessed'\n",
        "os.environ['RESULTS_FOLDER'] = '/content/nnUNet_results'\n",
        "\n",
        "\n",
        "os.makedirs('/content/clean_data_local/nnUNet_raw_data', exist_ok=True)\n",
        "os.makedirs('/content/nnUNet_preprocessed', exist_ok=True)\n",
        "os.makedirs('/content/nnUNet_results', exist_ok=True)\n",
        "\n",
        "print(\"nnUNet_raw_data_base =\", os.environ['nnUNet_raw_data_base'])\n",
        "print(\"nnUNet_preprocessed =\", os.environ['nnUNet_preprocessed'])\n",
        "print(\"RESULTS_FOLDER =\", os.environ['RESULTS_FOLDER'])"
      ],
      "metadata": {
        "id": "6NUyTiJeELDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df9afd0-0284-4a56-863f-874883ddea27"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nnUNet_raw_data_base = /content/clean_data_local/nnUNet_raw_data\n",
            "nnUNet_preprocessed = /content/nnUNet_preprocessed\n",
            "RESULTS_FOLDER = /content/nnUNet_results\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/clean_data_local/nnUNet_raw_data/nnUNet_raw_data/Task001_Glioma"
      ],
      "metadata": {
        "id": "ClkAbeliELlM"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/clean_data_local/nnUNet_raw_data/Task001_Glioma /content/clean_data_local/nnUNet_raw_data/nnUNet_raw_data/\n"
      ],
      "metadata": {
        "id": "J_nfpGZK5Xxw"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**inshallah ho jhaye ga**"
      ],
      "metadata": {
        "id": "3_R1kApz87Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNet_plan_and_preprocess -t 1 --verify_dataset_integrity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzYdAPrWqYr-",
        "outputId": "bea50c63-53ab-4d83-d484-15bc1fa439fc"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Please cite the following paper when using nnUNet:\n",
            "\n",
            "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
            "\n",
            "\n",
            "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
            "\n",
            "Verifying training set\n",
            "checking case PatientID_0003_Timepoint_1_0000\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/nnUNet_plan_and_preprocess\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nnunet/experiment_planning/nnUNet_plan_and_preprocess.py\", line 105, in main\n",
            "    verify_dataset_integrity(join(nnUNet_raw_data, task_name))\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/nnunet/preprocessing/sanity_checks.py\", line 129, in verify_dataset_integrity\n",
            "    assert isfile(expected_label_file), \"could not find label file for case %s. Expected file: \\n%s\" % (\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: could not find label file for case PatientID_0003_Timepoint_1_0000. Expected file: \n",
            "/content/clean_data_local/nnUNet_raw_data/nnUNet_raw_data/Task001_Glioma/labelsTr/PatientID_0003_Timepoint_1_0000.nii.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nnUNet_train 3d_fullres nnUNetTrainerV2 Task001_Glioma 0 --npz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5YdjAFrn_af",
        "outputId": "07bc6635-694e-46e7-82b5-192b69a1b413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nnUNet_train: command not found\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}